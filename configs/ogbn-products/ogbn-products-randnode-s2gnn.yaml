out_dir: tests/results
metric_best: accuracy
wandb:
  use: True
  project: ogbn-products
  entity: tum_i26
dataset:
  format: OGB
  name: ogbn-products
  task: node
  task_type: classification
  transductive: True
  node_encoder: True
  node_encoder_name: OGBNArxivNode
  edge_encoder: False
  ogbn_arxiv:
    mask_rate: ~
    use_labels: True
posenc_MagLapPE:
  enable: True
  q: 0.0
  largest_connected_component: True
  precompute: True
  max_freqs: 100
  laplacian_norm: rw
train:
  mode: custom
  batch_size: 1
  eval_period: 1
  ckpt_best: True
  ckpt_data_splits: ['val', 'test']
  ckpt_data_attrs: ['y', 'pred', 'batch', 'train_mask', 'val_mask', 'test_mask']
  sampler: random_node
  train_parts: 16
model:
  type: s2gnn
  loss_fun: cross_entropy_ogbn-arxiv
gnn:
  head: transductive_node
  layers_pre_mp: 0
  layers_mp: 6
  layers_post_mp: 1
  dim_inner: 256
  layer_type: gatconv
  stage_type: stack
  batchnorm: True
  act: relu
  dropout: 0.5
  agg: mean
  adj_norm: gcn
  residual: True
  gatconv:
    pre_dropout: 0.15
    num_heads: 8
    negative_slope: 0.2
    attn_dropout: 0.05
    feat_dropout: 0.5
    norm: False
    backend: PyG
    with_linear: True
  spectral:
    layer_skip: [0, 2, 3, 4]
    combine_with_spatial: True
    dropout: 0.4
    # For choosing the right cutoff:
    # for i in [49, 99, 149, 199, 299, 399, 499]:
    #   print(loaders[0].data.laplacian_eigenvalue_plain[0, i].item())
    # 0.011326365172863007
    # 0.015278191305696964
    # 0.018371259793639183
    # 0.02121509611606598
    # 0.026733025908470154
    # 0.03115316480398178
    # 0.035438474267721176
    # for i in [49, 99, 149, 199, 299, 399, 499]:
    #   print(1 / torch.pi * torch.acos(1 - loaders[0].data.laplacian_eigenvalue_plain[0, i]).item())
    # 0.04795361031142401
    # 0.05571292813834391
    # 0.06110855465286857
    # 0.06568379955708392
    # 0.07376691103934474
    # 0.07966178643670194
    # 0.08499505427274177
    frequency_cutoff: 0.01528
    filter_encoder: basis
    # drop_trailing_repeated: True
    feature_transform: ~  #glu
    filter_variant: silu_mix
    basis_bottleneck: 0.08
    num_heads_filter_encoder: -1
    basis_num_gaussians: 40
    learnable_norm: False  # True
    window: tukey
optim:
  clip_grad_norm: True
  optimizer: adamW
  weight_decay: 0.0
  base_lr: 0.0005
  max_epoch: 400
  scheduler: constant_with_warmup
  num_warmup_epochs: 20
  stop_patience: 300
device: cuda
