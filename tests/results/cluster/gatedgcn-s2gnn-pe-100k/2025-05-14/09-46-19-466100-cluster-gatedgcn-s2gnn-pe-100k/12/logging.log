[*] Run ID 12: seed=12, split_index=0
    Starting now: 2025-05-14 09:46:19.755863
[*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
  Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
  undirected: True
  num graphs: 12000
  avg num_nodes/graph: 117
  num node features: 7
  num edge features: 0
  num classes: 6
Precomputing Positional Encoding statistics: ['MagLapPE'] for all graphs...
  ...estimated to be undirected: True
Done! Took 00:02:52.12
GraphGymModule(
  (model): S2GNN(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): LinearNodeEncoder(
          (encoder): Linear(in_features=7, out_features=70, bias=True)
        )
        (encoder2): MagLapPENodeEncoder(
          (posenc_lin): Linear(in_features=50, out_features=70, bias=True)
        )
      )
    )
    (gnn_layers): Sequential(
      (0): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
      (1): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
      (2): FeatureBatchSpectralLayer(
        (filter): FilterEncoder(
          (filter): BasisFunctionsLayer(
            (distance_expansion): GaussianSmearing()
            (linear): Sequential(
              (0): Linear(in_features=50, out_features=70, bias=True)
            )
          )
        )
        (feature_transform): SpecFeatureTransformLayer(
          (layer_real): GLULayer(
            (lin1): Linear(in_features=70, out_features=70, bias=True)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (window): Window()
      )
      (3): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (mlp): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=70, out_features=70, bias=True)
        (2): GELU(approximate='none')
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=70, out_features=6, bias=True)
      )
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  arxiv_year:
    num_split: 0
    with_ogbn_arxiv_labels: False
  associative_recall:
    n_graphs: (25000, 500, 500)
    num_keys: 1
    num_vocab: 30
    precalc_eigdec_k: 10
    test_n_nodes: (1000, 1200)
    train_n_nodes: (20, 1000)
    valid_n_nodes: (20, 1000)
  cache_load: False
  cache_save: False
  custom_cluster:
    gmm_cluster_from_posterior: True
    gmm_dim: 2
    gmm_edges_max: 10
    gmm_edges_min: 1
    gmm_range_clusters: 10
    gmm_std_clusters: 2
    graph_type: gmm
    n_clusters: 6
    n_graphs: (10000, 1000, 1000)
    random_p: 0.55
    random_q: 0.25
    size_max: 35
    size_min: 5
  dir: ./datasets
  edge_dim: 128
  edge_encoder: False
  edge_encoder_bn: True
  edge_encoder_name: Bond
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG-GNNBenchmarkDataset
  label_column: none
  label_table: none
  location: local
  name: CLUSTER
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LinearNode+MagLapPE
  node_encoder_num_types: 0
  ogbn_arxiv:
    mask_rate: 0.5
    use_labels: True
  over_squashing:
    gen_mode: full
    n_classes: 5
    n_graphs: (5000, 500, 5000)
    test_n_nodes: (52, 100)
    topology: ring_lollipop
    train_n_nodes: (4, 50)
    valid_n_nodes: (4, 50)
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  source_dist:
    n_graphs: (50000, 2500, 2500)
    p_add_edges_from_tree: 0
    test_n_nodes: (1100, 1200)
    train_n_nodes: (500, 1000)
    valid_n_nodes: (1000, 1100)
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  tpu_graphs:
    config_node_readout: False
    custom: False
    drop_high_deg_sinks: False
    drop_high_deg_sources: False
    drop_last_node_above_deg: -1
    encoder_factor: 100.0
    include_valid_in_train: False
    normalize: False
    search: ['random']
    source: ['nlp']
    subsample: 500
    tpu_task: layout
  transductive: False
  transform: none
  tu_simple: True
device: cuda
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: gelu
  adj_norm: dir
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: False
  batchnorm_post_mp: False
  clear_feature: True
  dim_inner: 70
  dir_aggr: cat
  dropout: 0.1
  gatconv:
    attn_dropout: 0.05
    backend: PyG
    feat_dropout: 0.75
    negative_slope: 0.2
    norm: True
    num_heads: 3
    pre_dropout: 0.1
    with_linear: True
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_skip: []
  layer_type: gatedgcnconv
  layernorm_post_mp: False
  layers_mp: 3
  layers_post_mp: 2
  layers_pre_mp: 0
  make_undirected: True
  msg_direction: single
  node_dropout: 0.0
  normalize_adj: False
  residual: True
  self_msg: concat
  skip_every: 1
  spectral:
    basis_bottleneck: 1.0
    basis_init_type: default
    basis_num_gaussians: 50
    combine_with_spatial: None
    combine_with_spatial_norm: True
    dropout: -1.0
    eigv_scale: -1
    feature_transform: glu
    filter_encoder: basis
    filter_layers: 1
    filter_value_trans: None
    filter_variant: None
    frequency_cutoff: 1.3
    layer_skip: [0, 2]
    learnable_norm: True
    learnable_norm_init: 0
    mlp_layers_filter_encoder: 2
    num_heads_filter_encoder: -1
    readout: None
    readout_residual: False
    readout_sepnorm: False
    real_imag_x_merge: None
    residual: True
    window: tukey
  stage_type: stack
  use_edge_attr: False
gpu_mem: False
gt:
  attn_dropout: 0.0
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  dim_hidden: 64
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: SANLayer
  layers: 3
  n_heads: 8
  pna_degrees: []
  residual: True
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy-SBM
model:
  edge_decoding: dot
  graph_pooling: add
  list_mle_divisor: 250
  loss_fun: weighted_cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: s2gnn
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.001
  batch_accumulation: 1
  clip_grad_norm: True
  last_layer_no_wd: False
  lr_decay: 0.1
  max_epoch: 100
  min_lr: 0.0
  model_averaging: None
  model_averaging_start: 0
  momentum: 0.9
  num_warmup_epochs: 5
  optimizer: adamW
  quasi_alternating: -1
  reduce_factor: 0.1
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  stop_patience: 1000
  weight_decay: 0.0
out_dir: tests/results/cluster/gatedgcn-s2gnn-pe-100k/2025-05-14/09-46-19-466100-cluster-gatedgcn-s2gnn-pe-100k
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_MagLapPE:
  dim_pe: 0
  drop_trailing_repeated: False
  enable: True
  kwargs:
    
  laplacian_norm: sym
  largest_connected_component: False
  layers: 3
  max_freqs: 50
  model: none
  n_heads: 4
  pass_as_var: False
  positional_encoding: True
  post_layers: 0
  precompute: False
  q: 0.0
  raw_norm_type: none
  sparse: True
  which: SA
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: False
print: both
round: 5
run_dir: tests/results/cluster/gatedgcn-s2gnn-pe-100k/2025-05-14/09-46-19-466100-cluster-gatedgcn-s2gnn-pe-100k/12
run_id: 12
run_multiple_splits: []
seed: 12
share:
  dim_in: 7
  dim_out: 6
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: False
train:
  auto_resume: False
  batch_size: 128
  ckpt_best: True
  ckpt_clean: True
  ckpt_data_attrs: ['y', 'pred', 'batch']
  ckpt_data_splits: ['val', 'test']
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  num_sample_configs: 16
  radius: extend
  sample_node: False
  sampler: full_batch
  scale_num_sample_configs: True
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  num_sample_batch: 100
  num_sample_configs: 1000
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: tum_i26
  name: 
  project: cluster
  tags: 
  use: False
Num parameters: 93736
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 50.91014, 'eta': 5040.10424, 'eta_hours': 1.40003, 'loss': 1.85306629, 'lr': 0.0, 'params': 93736, 'time_iter': 0.64443, 'accuracy': 0.16022, 'f1': 0.07583, 'accuracy-SBM': 0.16046, 'auc': 0.48847}
...computing epoch stats took: 0.54s
val: {'epoch': 0, 'time_epoch': 3.17241, 'loss': 1.8346267, 'lr': 0, 'params': 93736, 'time_iter': 0.39655, 'accuracy': 0.15771, 'f1': 0.05204, 'accuracy-SBM': 0.15832, 'auc': 0.48691}
...computing epoch stats took: 0.38s
test: {'epoch': 0, 'time_epoch': 3.14912, 'loss': 1.83473971, 'lr': 0, 'params': 93736, 'time_iter': 0.39364, 'accuracy': 0.15541, 'f1': 0.05097, 'accuracy-SBM': 0.15737, 'auc': 0.48844}
...computing epoch stats took: 0.37s
> Epoch 0: took 58.5s (avg 58.5s) | Best so far: epoch 0	train loss: 1.8531 train_accuracy-SBM: 0.1605	val loss: 1.8346 val_accuracy-SBM: 0.1583	test loss: 1.8347 test_accuracy-SBM: 0.1574
