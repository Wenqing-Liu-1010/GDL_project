[*] Run ID 11: seed=11, split_index=0
    Starting now: 2025-05-13 22:20:57.998605
[*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
  Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
  undirected: True
  num graphs: 12000
  avg num_nodes/graph: 117
  num node features: 7
  num edge features: 0
  num classes: 6
GraphGymModule(
  (model): S2GNN(
    (encoder): FeatureEncoder(
      (node_encoder): LinearNodeEncoder(
        (encoder): Linear(in_features=7, out_features=70, bias=True)
      )
    )
    (gnn_layers): Sequential(
      (0): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
      (1): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
      (2): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
      (3): GatedGCNConvGNNLayer(
        (conv): GatedGCNLayer()
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (mlp): Sequential(
        (0): Dropout(p=0.0, inplace=False)
        (1): Linear(in_features=70, out_features=70, bias=True)
        (2): GELU(approximate='none')
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=70, out_features=6, bias=True)
      )
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  arxiv_year:
    num_split: 0
    with_ogbn_arxiv_labels: False
  associative_recall:
    n_graphs: (25000, 500, 500)
    num_keys: 1
    num_vocab: 30
    precalc_eigdec_k: 10
    test_n_nodes: (1000, 1200)
    train_n_nodes: (20, 1000)
    valid_n_nodes: (20, 1000)
  cache_load: False
  cache_save: False
  custom_cluster:
    gmm_cluster_from_posterior: True
    gmm_dim: 2
    gmm_edges_max: 10
    gmm_edges_min: 1
    gmm_range_clusters: 10
    gmm_std_clusters: 2
    graph_type: gmm
    n_clusters: 6
    n_graphs: (10000, 1000, 1000)
    random_p: 0.55
    random_q: 0.25
    size_max: 35
    size_min: 5
  dir: ./datasets
  edge_dim: 128
  edge_encoder: False
  edge_encoder_bn: True
  edge_encoder_name: Bond
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG-GNNBenchmarkDataset
  label_column: none
  label_table: none
  location: local
  name: CLUSTER
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LinearNode
  node_encoder_num_types: 0
  ogbn_arxiv:
    mask_rate: 0.5
    use_labels: True
  over_squashing:
    gen_mode: full
    n_classes: 5
    n_graphs: (5000, 500, 5000)
    test_n_nodes: (52, 100)
    topology: ring_lollipop
    train_n_nodes: (4, 50)
    valid_n_nodes: (4, 50)
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  source_dist:
    n_graphs: (50000, 2500, 2500)
    p_add_edges_from_tree: 0
    test_n_nodes: (1100, 1200)
    train_n_nodes: (500, 1000)
    valid_n_nodes: (1000, 1100)
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  tpu_graphs:
    config_node_readout: False
    custom: False
    drop_high_deg_sinks: False
    drop_high_deg_sources: False
    drop_last_node_above_deg: -1
    encoder_factor: 100.0
    include_valid_in_train: False
    normalize: False
    search: ['random']
    source: ['nlp']
    subsample: 500
    tpu_task: layout
  transductive: False
  transform: none
  tu_simple: True
device: cuda
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: gelu
  adj_norm: dir
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: False
  batchnorm_post_mp: False
  clear_feature: True
  dim_inner: 70
  dir_aggr: cat
  dropout: 0.0
  gatconv:
    attn_dropout: 0.05
    backend: PyG
    feat_dropout: 0.75
    negative_slope: 0.2
    norm: True
    num_heads: 3
    pre_dropout: 0.1
    with_linear: True
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_skip: []
  layer_type: gatedgcnconv
  layernorm_post_mp: False
  layers_mp: 4
  layers_post_mp: 2
  layers_pre_mp: 0
  make_undirected: True
  msg_direction: single
  node_dropout: 0.0
  normalize_adj: False
  residual: True
  self_msg: concat
  skip_every: 1
  spectral:
    basis_bottleneck: 0.25
    basis_init_type: default
    basis_num_gaussians: 50
    combine_with_spatial: None
    combine_with_spatial_norm: True
    dropout: -1.0
    eigv_scale: -1
    feature_transform: None
    filter_encoder: basis
    filter_layers: 1
    filter_value_trans: None
    filter_variant: naive
    frequency_cutoff: None
    layer_skip: [-1]
    learnable_norm: False
    learnable_norm_init: 0
    mlp_layers_filter_encoder: 2
    num_heads_filter_encoder: -1
    readout: None
    readout_residual: False
    readout_sepnorm: False
    real_imag_x_merge: None
    residual: True
    window: None
  stage_type: stack
  use_edge_attr: False
gpu_mem: False
gt:
  attn_dropout: 0.0
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  dim_hidden: 64
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: SANLayer
  layers: 3
  n_heads: 8
  pna_degrees: []
  residual: True
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy-SBM
model:
  edge_decoding: dot
  graph_pooling: add
  list_mle_divisor: 250
  loss_fun: weighted_cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: s2gnn
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.001
  batch_accumulation: 1
  clip_grad_norm: True
  last_layer_no_wd: False
  lr_decay: 0.1
  max_epoch: 50
  min_lr: 0.0
  model_averaging: None
  model_averaging_start: 0
  momentum: 0.9
  num_warmup_epochs: 5
  optimizer: adamW
  quasi_alternating: -1
  reduce_factor: 0.1
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  stop_patience: 1000
  weight_decay: 0.0
out_dir: tests/results/cluster/gatedgcn-100k/2025-05-13/22-20-57-778547-cluster-gatedgcn-100k
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_MagLapPE:
  dim_pe: 0
  drop_trailing_repeated: False
  enable: False
  kwargs:
    
  laplacian_norm: sym
  largest_connected_component: True
  layers: 3
  max_freqs: 10
  model: none
  n_heads: 4
  pass_as_var: False
  positional_encoding: False
  post_layers: 0
  precompute: False
  q: 5e-06
  raw_norm_type: none
  sparse: True
  which: SA
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: False
print: both
round: 5
run_dir: tests/results/cluster/gatedgcn-100k/2025-05-13/22-20-57-778547-cluster-gatedgcn-100k/11
run_id: 11
run_multiple_splits: []
seed: 11
share:
  dim_in: 7
  dim_out: 6
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: False
train:
  auto_resume: False
  batch_size: 128
  ckpt_best: True
  ckpt_clean: True
  ckpt_data_attrs: ['y', 'pred', 'batch']
  ckpt_data_splits: ['val', 'test']
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  num_sample_configs: 16
  radius: extend
  sample_node: False
  sampler: full_batch
  scale_num_sample_configs: True
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  num_sample_batch: 100
  num_sample_configs: 1000
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: tum_i26
  name: 
  project: cluster
  tags: 
  use: False
Num parameters: 106476
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 29.64995, 'eta': 1452.84766, 'eta_hours': 0.40357, 'loss': 1.8431124, 'lr': 0.0, 'params': 106476, 'time_iter': 0.37532, 'accuracy': 0.16832, 'f1': 0.11104, 'accuracy-SBM': 0.16828, 'auc': 0.49735}
...computing epoch stats took: 0.56s
val: {'epoch': 0, 'time_epoch': 1.79708, 'loss': 1.83399841, 'lr': 0, 'params': 106476, 'time_iter': 0.22464, 'accuracy': 0.17687, 'f1': 0.1074, 'accuracy-SBM': 0.17815, 'auc': 0.50967}
...computing epoch stats took: 0.36s
test: {'epoch': 0, 'time_epoch': 1.81839, 'loss': 1.83411983, 'lr': 0, 'params': 106476, 'time_iter': 0.2273, 'accuracy': 0.17831, 'f1': 0.10796, 'accuracy-SBM': 0.17831, 'auc': 0.51171}
...computing epoch stats took: 0.36s
> Epoch 0: took 34.6s (avg 34.6s) | Best so far: epoch 0	train loss: 1.8431 train_accuracy-SBM: 0.1683	val loss: 1.8340 val_accuracy-SBM: 0.1782	test loss: 1.8341 test_accuracy-SBM: 0.1783
train: {'epoch': 1, 'time_epoch': 28.47239, 'eta': 1394.93632, 'eta_hours': 0.38748, 'loss': 1.61606129, 'lr': 0.0002, 'params': 106476, 'time_iter': 0.36041, 'accuracy': 0.34429, 'f1': 0.33813, 'accuracy-SBM': 0.3443, 'auc': 0.69669}
...computing epoch stats took: 0.46s
val: {'epoch': 1, 'time_epoch': 1.76616, 'loss': 1.92723285, 'lr': 0, 'params': 106476, 'time_iter': 0.22077, 'accuracy': 0.23982, 'f1': 0.1821, 'accuracy-SBM': 0.23997, 'auc': 0.70388}
...computing epoch stats took: 0.41s
test: {'epoch': 1, 'time_epoch': 1.72839, 'loss': 1.92453528, 'lr': 0, 'params': 106476, 'time_iter': 0.21605, 'accuracy': 0.24187, 'f1': 0.18662, 'accuracy-SBM': 0.24376, 'auc': 0.70468}
...computing epoch stats took: 0.36s
> Epoch 1: took 33.2s (avg 33.9s) | Best so far: epoch 1	train loss: 1.6161 train_accuracy-SBM: 0.3443	val loss: 1.9272 val_accuracy-SBM: 0.2400	test loss: 1.9245 test_accuracy-SBM: 0.2438
train: {'epoch': 2, 'time_epoch': 28.54594, 'eta': 1357.80311, 'eta_hours': 0.37717, 'loss': 1.40474839, 'lr': 0.0004, 'params': 106476, 'time_iter': 0.36134, 'accuracy': 0.45954, 'f1': 0.4595, 'accuracy-SBM': 0.45954, 'auc': 0.78621}
...computing epoch stats took: 0.47s
val: {'epoch': 2, 'time_epoch': 1.782, 'loss': 2.06741372, 'lr': 0, 'params': 106476, 'time_iter': 0.22275, 'accuracy': 0.26459, 'f1': 0.21156, 'accuracy-SBM': 0.26722, 'auc': 0.74423}
...computing epoch stats took: 0.36s
test: {'epoch': 2, 'time_epoch': 1.72438, 'loss': 2.04709704, 'lr': 0, 'params': 106476, 'time_iter': 0.21555, 'accuracy': 0.27166, 'f1': 0.21884, 'accuracy-SBM': 0.27192, 'auc': 0.74615}
...computing epoch stats took: 0.36s
> Epoch 2: took 33.3s (avg 33.7s) | Best so far: epoch 2	train loss: 1.4047 train_accuracy-SBM: 0.4595	val loss: 2.0674 val_accuracy-SBM: 0.2672	test loss: 2.0471 test_accuracy-SBM: 0.2719
train: {'epoch': 3, 'time_epoch': 28.45853, 'eta': 1323.95836, 'eta_hours': 0.36777, 'loss': 1.33565962, 'lr': 0.0006, 'params': 106476, 'time_iter': 0.36023, 'accuracy': 0.48946, 'f1': 0.48946, 'accuracy-SBM': 0.48946, 'auc': 0.81006}
val: {'epoch': 3, 'time_epoch': 1.77605, 'loss': 3.17422939, 'lr': 0, 'params': 106476, 'time_iter': 0.22201, 'accuracy': 0.28779, 'f1': 0.19654, 'accuracy-SBM': 0.28503, 'auc': 0.72468}
test: {'epoch': 3, 'time_epoch': 1.71913, 'loss': 3.18001031, 'lr': 0, 'params': 106476, 'time_iter': 0.21489, 'accuracy': 0.28265, 'f1': 0.195, 'accuracy-SBM': 0.28369, 'auc': 0.72312}
> Epoch 3: took 33.2s (avg 33.6s) | Best so far: epoch 3	train loss: 1.3357 train_accuracy-SBM: 0.4895	val loss: 3.1742 val_accuracy-SBM: 0.2850	test loss: 3.1800 test_accuracy-SBM: 0.2837
train: {'epoch': 4, 'time_epoch': 28.49635, 'eta': 1292.60847, 'eta_hours': 0.35906, 'loss': 1.23780207, 'lr': 0.0008, 'params': 106476, 'time_iter': 0.36071, 'accuracy': 0.53543, 'f1': 0.53542, 'accuracy-SBM': 0.53543, 'auc': 0.83986}
val: {'epoch': 4, 'time_epoch': 1.75022, 'loss': 1.69389294, 'lr': 0, 'params': 106476, 'time_iter': 0.21878, 'accuracy': 0.33072, 'f1': 0.27466, 'accuracy-SBM': 0.32908, 'auc': 0.77267}
test: {'epoch': 4, 'time_epoch': 1.72814, 'loss': 1.69179543, 'lr': 0, 'params': 106476, 'time_iter': 0.21602, 'accuracy': 0.3284, 'f1': 0.27366, 'accuracy-SBM': 0.32854, 'auc': 0.7722}
> Epoch 4: took 33.2s (avg 33.5s) | Best so far: epoch 4	train loss: 1.2378 train_accuracy-SBM: 0.5354	val loss: 1.6939 val_accuracy-SBM: 0.3291	test loss: 1.6918 test_accuracy-SBM: 0.3285
train: {'epoch': 5, 'time_epoch': 28.59781, 'eta': 1262.9538, 'eta_hours': 0.35082, 'loss': 1.17175353, 'lr': 0.001, 'params': 106476, 'time_iter': 0.362, 'accuracy': 0.56399, 'f1': 0.56399, 'accuracy-SBM': 0.56399, 'auc': 0.85779}
val: {'epoch': 5, 'time_epoch': 1.78209, 'loss': 1.52106955, 'lr': 0, 'params': 106476, 'time_iter': 0.22276, 'accuracy': 0.42226, 'f1': 0.37746, 'accuracy-SBM': 0.42506, 'auc': 0.79705}
test: {'epoch': 5, 'time_epoch': 1.73122, 'loss': 1.51187571, 'lr': 0, 'params': 106476, 'time_iter': 0.2164, 'accuracy': 0.42702, 'f1': 0.38373, 'accuracy-SBM': 0.42833, 'auc': 0.79853}
> Epoch 5: took 33.3s (avg 33.5s) | Best so far: epoch 5	train loss: 1.1718 train_accuracy-SBM: 0.5640	val loss: 1.5211 val_accuracy-SBM: 0.4251	test loss: 1.5119 test_accuracy-SBM: 0.4283
train: {'epoch': 6, 'time_epoch': 28.53166, 'eta': 1233.19476, 'eta_hours': 0.34255, 'loss': 1.15270897, 'lr': 0.00099878, 'params': 106476, 'time_iter': 0.36116, 'accuracy': 0.57129, 'f1': 0.57128, 'accuracy-SBM': 0.57129, 'auc': 0.86271}
val: {'epoch': 6, 'time_epoch': 1.76287, 'loss': 2.42540813, 'lr': 0, 'params': 106476, 'time_iter': 0.22036, 'accuracy': 0.29289, 'f1': 0.2429, 'accuracy-SBM': 0.29178, 'auc': 0.75097}
test: {'epoch': 6, 'time_epoch': 1.72316, 'loss': 2.39196461, 'lr': 0, 'params': 106476, 'time_iter': 0.21539, 'accuracy': 0.29864, 'f1': 0.24947, 'accuracy-SBM': 0.29623, 'auc': 0.75098}
> Epoch 6: took 33.2s (avg 33.4s) | Best so far: epoch 5	train loss: 1.1718 train_accuracy-SBM: 0.5640	val loss: 1.5211 val_accuracy-SBM: 0.4251	test loss: 1.5119 test_accuracy-SBM: 0.4283
train: {'epoch': 7, 'time_epoch': 28.52759, 'eta': 1203.72121, 'eta_hours': 0.33437, 'loss': 1.14141349, 'lr': 0.00099513, 'params': 106476, 'time_iter': 0.36111, 'accuracy': 0.57541, 'f1': 0.5754, 'accuracy-SBM': 0.57541, 'auc': 0.86554}
val: {'epoch': 7, 'time_epoch': 1.75703, 'loss': 2.09386566, 'lr': 0, 'params': 106476, 'time_iter': 0.21963, 'accuracy': 0.28725, 'f1': 0.24465, 'accuracy-SBM': 0.28687, 'auc': 0.75795}
test: {'epoch': 7, 'time_epoch': 1.73432, 'loss': 2.06035794, 'lr': 0, 'params': 106476, 'time_iter': 0.21679, 'accuracy': 0.29571, 'f1': 0.2551, 'accuracy-SBM': 0.29359, 'auc': 0.76019}
> Epoch 7: took 33.2s (avg 33.4s) | Best so far: epoch 5	train loss: 1.1718 train_accuracy-SBM: 0.5640	val loss: 1.5211 val_accuracy-SBM: 0.4251	test loss: 1.5119 test_accuracy-SBM: 0.4283
train: {'epoch': 8, 'time_epoch': 28.37112, 'eta': 1173.74503, 'eta_hours': 0.32604, 'loss': 1.13562654, 'lr': 0.00098907, 'params': 106476, 'time_iter': 0.35913, 'accuracy': 0.57806, 'f1': 0.57806, 'accuracy-SBM': 0.57806, 'auc': 0.86699}
val: {'epoch': 8, 'time_epoch': 1.76678, 'loss': 1.59383736, 'lr': 0, 'params': 106476, 'time_iter': 0.22085, 'accuracy': 0.40686, 'f1': 0.36173, 'accuracy-SBM': 0.40724, 'auc': 0.80629}
test: {'epoch': 8, 'time_epoch': 1.72236, 'loss': 1.58896815, 'lr': 0, 'params': 106476, 'time_iter': 0.21529, 'accuracy': 0.40644, 'f1': 0.36325, 'accuracy-SBM': 0.40831, 'auc': 0.8074}
> Epoch 8: took 33.1s (avg 33.4s) | Best so far: epoch 5	train loss: 1.1718 train_accuracy-SBM: 0.5640	val loss: 1.5211 val_accuracy-SBM: 0.4251	test loss: 1.5119 test_accuracy-SBM: 0.4283
train: {'epoch': 9, 'time_epoch': 28.5204, 'eta': 1144.68698, 'eta_hours': 0.31797, 'loss': 1.12908276, 'lr': 0.00098063, 'params': 106476, 'time_iter': 0.36102, 'accuracy': 0.58023, 'f1': 0.58023, 'accuracy-SBM': 0.58024, 'auc': 0.86862}
val: {'epoch': 9, 'time_epoch': 1.76848, 'loss': 2.29091064, 'lr': 0, 'params': 106476, 'time_iter': 0.22106, 'accuracy': 0.28329, 'f1': 0.25096, 'accuracy-SBM': 0.2843, 'auc': 0.78972}
test: {'epoch': 9, 'time_epoch': 1.72876, 'loss': 2.26995912, 'lr': 0, 'params': 106476, 'time_iter': 0.21609, 'accuracy': 0.28758, 'f1': 0.25743, 'accuracy-SBM': 0.28822, 'auc': 0.78976}
> Epoch 9: took 33.2s (avg 33.3s) | Best so far: epoch 5	train loss: 1.1718 train_accuracy-SBM: 0.5640	val loss: 1.5211 val_accuracy-SBM: 0.4251	test loss: 1.5119 test_accuracy-SBM: 0.4283
train: {'epoch': 10, 'time_epoch': 28.72449, 'eta': 1116.45028, 'eta_hours': 0.31013, 'loss': 1.12534545, 'lr': 0.00096985, 'params': 106476, 'time_iter': 0.3636, 'accuracy': 0.58174, 'f1': 0.58174, 'accuracy-SBM': 0.58174, 'auc': 0.86954}
val: {'epoch': 10, 'time_epoch': 1.7751, 'loss': 1.50744464, 'lr': 0, 'params': 106476, 'time_iter': 0.22189, 'accuracy': 0.44331, 'f1': 0.42226, 'accuracy-SBM': 0.44265, 'auc': 0.80762}
test: {'epoch': 10, 'time_epoch': 1.71636, 'loss': 1.49707265, 'lr': 0, 'params': 106476, 'time_iter': 0.21455, 'accuracy': 0.44488, 'f1': 0.42503, 'accuracy-SBM': 0.44449, 'auc': 0.80846}
> Epoch 10: took 33.5s (avg 33.4s) | Best so far: epoch 10	train loss: 1.1253 train_accuracy-SBM: 0.5817	val loss: 1.5074 val_accuracy-SBM: 0.4426	test loss: 1.4971 test_accuracy-SBM: 0.4445
train: {'epoch': 11, 'time_epoch': 28.64028, 'eta': 1087.86561, 'eta_hours': 0.30218, 'loss': 1.12212499, 'lr': 0.00095677, 'params': 106476, 'time_iter': 0.36254, 'accuracy': 0.58317, 'f1': 0.58317, 'accuracy-SBM': 0.58317, 'auc': 0.87032}
val: {'epoch': 11, 'time_epoch': 1.7493, 'loss': 1.58611219, 'lr': 0, 'params': 106476, 'time_iter': 0.21866, 'accuracy': 0.39746, 'f1': 0.36916, 'accuracy-SBM': 0.39794, 'auc': 0.79396}
test: {'epoch': 11, 'time_epoch': 1.72648, 'loss': 1.57418901, 'lr': 0, 'params': 106476, 'time_iter': 0.21581, 'accuracy': 0.40331, 'f1': 0.37654, 'accuracy-SBM': 0.40234, 'auc': 0.79534}
> Epoch 11: took 33.3s (avg 33.4s) | Best so far: epoch 10	train loss: 1.1253 train_accuracy-SBM: 0.5817	val loss: 1.5074 val_accuracy-SBM: 0.4426	test loss: 1.4971 test_accuracy-SBM: 0.4445
train: {'epoch': 12, 'time_epoch': 28.56119, 'eta': 1059.04729, 'eta_hours': 0.29418, 'loss': 1.11900948, 'lr': 0.00094147, 'params': 106476, 'time_iter': 0.36153, 'accuracy': 0.58409, 'f1': 0.58409, 'accuracy-SBM': 0.58409, 'auc': 0.87108}
val: {'epoch': 12, 'time_epoch': 1.76475, 'loss': 1.33353393, 'lr': 0, 'params': 106476, 'time_iter': 0.22059, 'accuracy': 0.50178, 'f1': 0.49449, 'accuracy-SBM': 0.50147, 'auc': 0.83697}
test: {'epoch': 12, 'time_epoch': 1.73355, 'loss': 1.33036309, 'lr': 0, 'params': 106476, 'time_iter': 0.21669, 'accuracy': 0.50356, 'f1': 0.49744, 'accuracy-SBM': 0.50337, 'auc': 0.83644}
> Epoch 12: took 33.3s (avg 33.4s) | Best so far: epoch 12	train loss: 1.1190 train_accuracy-SBM: 0.5841	val loss: 1.3335 val_accuracy-SBM: 0.5015	test loss: 1.3304 test_accuracy-SBM: 0.5034
train: {'epoch': 13, 'time_epoch': 28.56603, 'eta': 1030.27815, 'eta_hours': 0.28619, 'loss': 1.11534768, 'lr': 0.00092402, 'params': 106476, 'time_iter': 0.3616, 'accuracy': 0.58563, 'f1': 0.58563, 'accuracy-SBM': 0.58563, 'auc': 0.87197}
val: {'epoch': 13, 'time_epoch': 1.75354, 'loss': 1.32116014, 'lr': 0, 'params': 106476, 'time_iter': 0.21919, 'accuracy': 0.48374, 'f1': 0.48427, 'accuracy-SBM': 0.48397, 'auc': 0.83582}
test: {'epoch': 13, 'time_epoch': 1.72277, 'loss': 1.31671032, 'lr': 0, 'params': 106476, 'time_iter': 0.21535, 'accuracy': 0.48708, 'f1': 0.48807, 'accuracy-SBM': 0.48712, 'auc': 0.83614}
> Epoch 13: took 33.3s (avg 33.3s) | Best so far: epoch 12	train loss: 1.1190 train_accuracy-SBM: 0.5841	val loss: 1.3335 val_accuracy-SBM: 0.5015	test loss: 1.3304 test_accuracy-SBM: 0.5034
train: {'epoch': 14, 'time_epoch': 28.49419, 'eta': 1001.36847, 'eta_hours': 0.27816, 'loss': 1.11350423, 'lr': 0.00090451, 'params': 106476, 'time_iter': 0.36069, 'accuracy': 0.5862, 'f1': 0.5862, 'accuracy-SBM': 0.5862, 'auc': 0.87242}
val: {'epoch': 14, 'time_epoch': 1.74281, 'loss': 1.52103519, 'lr': 0, 'params': 106476, 'time_iter': 0.21785, 'accuracy': 0.43005, 'f1': 0.40379, 'accuracy-SBM': 0.43206, 'auc': 0.80609}
test: {'epoch': 14, 'time_epoch': 1.72173, 'loss': 1.50128646, 'lr': 0, 'params': 106476, 'time_iter': 0.21522, 'accuracy': 0.43723, 'f1': 0.41165, 'accuracy-SBM': 0.43758, 'auc': 0.80818}
> Epoch 14: took 33.2s (avg 33.3s) | Best so far: epoch 12	train loss: 1.1190 train_accuracy-SBM: 0.5841	val loss: 1.3335 val_accuracy-SBM: 0.5015	test loss: 1.3304 test_accuracy-SBM: 0.5034
train: {'epoch': 15, 'time_epoch': 28.49438, 'eta': 972.51112, 'eta_hours': 0.27014, 'loss': 1.11043447, 'lr': 0.00088302, 'params': 106476, 'time_iter': 0.36069, 'accuracy': 0.58729, 'f1': 0.58729, 'accuracy-SBM': 0.58729, 'auc': 0.87315}
val: {'epoch': 15, 'time_epoch': 1.76625, 'loss': 1.37186342, 'lr': 0, 'params': 106476, 'time_iter': 0.22078, 'accuracy': 0.49612, 'f1': 0.47718, 'accuracy-SBM': 0.49672, 'auc': 0.84091}
test: {'epoch': 15, 'time_epoch': 1.73133, 'loss': 1.36269999, 'lr': 0, 'params': 106476, 'time_iter': 0.21642, 'accuracy': 0.49955, 'f1': 0.48162, 'accuracy-SBM': 0.50039, 'auc': 0.84202}
> Epoch 15: took 33.2s (avg 33.3s) | Best so far: epoch 12	train loss: 1.1190 train_accuracy-SBM: 0.5841	val loss: 1.3335 val_accuracy-SBM: 0.5015	test loss: 1.3304 test_accuracy-SBM: 0.5034
train: {'epoch': 16, 'time_epoch': 28.53122, 'eta': 943.768, 'eta_hours': 0.26216, 'loss': 1.10841609, 'lr': 0.00085967, 'params': 106476, 'time_iter': 0.36115, 'accuracy': 0.58781, 'f1': 0.58781, 'accuracy-SBM': 0.58781, 'auc': 0.87364}
val: {'epoch': 16, 'time_epoch': 1.77063, 'loss': 1.53092279, 'lr': 0, 'params': 106476, 'time_iter': 0.22133, 'accuracy': 0.43511, 'f1': 0.41038, 'accuracy-SBM': 0.43571, 'auc': 0.8135}
test: {'epoch': 16, 'time_epoch': 1.75775, 'loss': 1.51841708, 'lr': 0, 'params': 106476, 'time_iter': 0.21972, 'accuracy': 0.44284, 'f1': 0.4192, 'accuracy-SBM': 0.44159, 'auc': 0.81525}
> Epoch 16: took 33.3s (avg 33.3s) | Best so far: epoch 12	train loss: 1.1190 train_accuracy-SBM: 0.5841	val loss: 1.3335 val_accuracy-SBM: 0.5015	test loss: 1.3304 test_accuracy-SBM: 0.5034
train: {'epoch': 17, 'time_epoch': 28.56396, 'eta': 915.10661, 'eta_hours': 0.2542, 'loss': 1.10635311, 'lr': 0.00083457, 'params': 106476, 'time_iter': 0.36157, 'accuracy': 0.5888, 'f1': 0.5888, 'accuracy-SBM': 0.5888, 'auc': 0.87416}
val: {'epoch': 17, 'time_epoch': 1.74418, 'loss': 1.39035958, 'lr': 0, 'params': 106476, 'time_iter': 0.21802, 'accuracy': 0.46182, 'f1': 0.44446, 'accuracy-SBM': 0.46033, 'auc': 0.82656}
test: {'epoch': 17, 'time_epoch': 1.71061, 'loss': 1.39128633, 'lr': 0, 'params': 106476, 'time_iter': 0.21383, 'accuracy': 0.46067, 'f1': 0.44382, 'accuracy-SBM': 0.46067, 'auc': 0.82631}
> Epoch 17: took 33.3s (avg 33.3s) | Best so far: epoch 12	train loss: 1.1190 train_accuracy-SBM: 0.5841	val loss: 1.3335 val_accuracy-SBM: 0.5015	test loss: 1.3304 test_accuracy-SBM: 0.5034
train: {'epoch': 18, 'time_epoch': 28.61459, 'eta': 886.5381, 'eta_hours': 0.24626, 'loss': 1.10428315, 'lr': 0.00080783, 'params': 106476, 'time_iter': 0.36221, 'accuracy': 0.58949, 'f1': 0.58949, 'accuracy-SBM': 0.58949, 'auc': 0.87464}
val: {'epoch': 18, 'time_epoch': 1.74651, 'loss': 1.27423886, 'lr': 0, 'params': 106476, 'time_iter': 0.21831, 'accuracy': 0.51607, 'f1': 0.50715, 'accuracy-SBM': 0.51607, 'auc': 0.84447}
test: {'epoch': 18, 'time_epoch': 1.72802, 'loss': 1.27792428, 'lr': 0, 'params': 106476, 'time_iter': 0.216, 'accuracy': 0.51429, 'f1': 0.50653, 'accuracy-SBM': 0.51523, 'auc': 0.8436}
> Epoch 18: took 33.3s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 19, 'time_epoch': 28.54261, 'eta': 857.85701, 'eta_hours': 0.23829, 'loss': 1.10076865, 'lr': 0.0007796, 'params': 106476, 'time_iter': 0.3613, 'accuracy': 0.5909, 'f1': 0.5909, 'accuracy-SBM': 0.5909, 'auc': 0.87548}
val: {'epoch': 19, 'time_epoch': 1.76151, 'loss': 1.31171878, 'lr': 0, 'params': 106476, 'time_iter': 0.22019, 'accuracy': 0.50454, 'f1': 0.49591, 'accuracy-SBM': 0.50396, 'auc': 0.83565}
test: {'epoch': 19, 'time_epoch': 1.72913, 'loss': 1.29943074, 'lr': 0, 'params': 106476, 'time_iter': 0.21614, 'accuracy': 0.50792, 'f1': 0.49935, 'accuracy-SBM': 0.50727, 'auc': 0.83776}
> Epoch 19: took 33.2s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 20, 'time_epoch': 28.62481, 'eta': 829.30261, 'eta_hours': 0.23036, 'loss': 1.09971665, 'lr': 0.00075, 'params': 106476, 'time_iter': 0.36234, 'accuracy': 0.59118, 'f1': 0.59118, 'accuracy-SBM': 0.59118, 'auc': 0.87574}
val: {'epoch': 20, 'time_epoch': 1.75437, 'loss': 1.32914035, 'lr': 0, 'params': 106476, 'time_iter': 0.2193, 'accuracy': 0.49333, 'f1': 0.47831, 'accuracy-SBM': 0.49358, 'auc': 0.8268}
test: {'epoch': 20, 'time_epoch': 1.75363, 'loss': 1.32279044, 'lr': 0, 'params': 106476, 'time_iter': 0.2192, 'accuracy': 0.49633, 'f1': 0.48131, 'accuracy-SBM': 0.49534, 'auc': 0.82777}
> Epoch 20: took 33.4s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 21, 'time_epoch': 28.44417, 'eta': 800.51192, 'eta_hours': 0.22236, 'loss': 1.09814113, 'lr': 0.00071919, 'params': 106476, 'time_iter': 0.36005, 'accuracy': 0.59191, 'f1': 0.59191, 'accuracy-SBM': 0.59191, 'auc': 0.87612}
val: {'epoch': 21, 'time_epoch': 1.75305, 'loss': 1.28751163, 'lr': 0, 'params': 106476, 'time_iter': 0.21913, 'accuracy': 0.51202, 'f1': 0.50899, 'accuracy-SBM': 0.51045, 'auc': 0.84891}
test: {'epoch': 21, 'time_epoch': 1.73344, 'loss': 1.28462256, 'lr': 0, 'params': 106476, 'time_iter': 0.21668, 'accuracy': 0.51381, 'f1': 0.51178, 'accuracy-SBM': 0.51308, 'auc': 0.84967}
> Epoch 21: took 33.1s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 22, 'time_epoch': 28.62009, 'eta': 771.95787, 'eta_hours': 0.21443, 'loss': 1.09625736, 'lr': 0.0006873, 'params': 106476, 'time_iter': 0.36228, 'accuracy': 0.59243, 'f1': 0.59243, 'accuracy-SBM': 0.59243, 'auc': 0.87656}
val: {'epoch': 22, 'time_epoch': 1.7616, 'loss': 1.31886057, 'lr': 0, 'params': 106476, 'time_iter': 0.2202, 'accuracy': 0.4947, 'f1': 0.4876, 'accuracy-SBM': 0.49453, 'auc': 0.83149}
test: {'epoch': 22, 'time_epoch': 1.73943, 'loss': 1.31431427, 'lr': 0, 'params': 106476, 'time_iter': 0.21743, 'accuracy': 0.49656, 'f1': 0.49017, 'accuracy-SBM': 0.49562, 'auc': 0.8322}
> Epoch 22: took 33.3s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 23, 'time_epoch': 28.51494, 'eta': 743.2844, 'eta_hours': 0.20647, 'loss': 1.09422825, 'lr': 0.00065451, 'params': 106476, 'time_iter': 0.36095, 'accuracy': 0.5935, 'f1': 0.5935, 'accuracy-SBM': 0.5935, 'auc': 0.87703}
val: {'epoch': 23, 'time_epoch': 1.78538, 'loss': 1.4511773, 'lr': 0, 'params': 106476, 'time_iter': 0.22317, 'accuracy': 0.47748, 'f1': 0.47764, 'accuracy-SBM': 0.47565, 'auc': 0.8416}
test: {'epoch': 23, 'time_epoch': 1.72747, 'loss': 1.43586628, 'lr': 0, 'params': 106476, 'time_iter': 0.21593, 'accuracy': 0.47924, 'f1': 0.48017, 'accuracy-SBM': 0.4793, 'auc': 0.84299}
> Epoch 23: took 33.2s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 24, 'time_epoch': 28.51633, 'eta': 714.62501, 'eta_hours': 0.19851, 'loss': 1.09220862, 'lr': 0.00062096, 'params': 106476, 'time_iter': 0.36097, 'accuracy': 0.5941, 'f1': 0.5941, 'accuracy-SBM': 0.5941, 'auc': 0.87751}
val: {'epoch': 24, 'time_epoch': 1.74778, 'loss': 1.390364, 'lr': 0, 'params': 106476, 'time_iter': 0.21847, 'accuracy': 0.47773, 'f1': 0.46976, 'accuracy-SBM': 0.47648, 'auc': 0.84137}
test: {'epoch': 24, 'time_epoch': 1.7413, 'loss': 1.38661828, 'lr': 0, 'params': 106476, 'time_iter': 0.21766, 'accuracy': 0.478, 'f1': 0.47154, 'accuracy-SBM': 0.47728, 'auc': 0.84152}
> Epoch 24: took 33.2s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 25, 'time_epoch': 28.50336, 'eta': 685.96464, 'eta_hours': 0.19055, 'loss': 1.0914648, 'lr': 0.00058682, 'params': 106476, 'time_iter': 0.3608, 'accuracy': 0.59435, 'f1': 0.59435, 'accuracy-SBM': 0.59435, 'auc': 0.87769}
val: {'epoch': 25, 'time_epoch': 1.75904, 'loss': 1.56726701, 'lr': 0, 'params': 106476, 'time_iter': 0.21988, 'accuracy': 0.45678, 'f1': 0.44089, 'accuracy-SBM': 0.45426, 'auc': 0.82773}
test: {'epoch': 25, 'time_epoch': 1.72806, 'loss': 1.5470613, 'lr': 0, 'params': 106476, 'time_iter': 0.21601, 'accuracy': 0.45996, 'f1': 0.44594, 'accuracy-SBM': 0.45869, 'auc': 0.82982}
> Epoch 25: took 33.2s (avg 33.3s) | Best so far: epoch 18	train loss: 1.1043 train_accuracy-SBM: 0.5895	val loss: 1.2742 val_accuracy-SBM: 0.5161	test loss: 1.2779 test_accuracy-SBM: 0.5152
train: {'epoch': 26, 'time_epoch': 28.47669, 'eta': 657.2932, 'eta_hours': 0.18258, 'loss': 1.08929635, 'lr': 0.00055226, 'params': 106476, 'time_iter': 0.36046, 'accuracy': 0.59525, 'f1': 0.59525, 'accuracy-SBM': 0.59525, 'auc': 0.87821}
val: {'epoch': 26, 'time_epoch': 1.75337, 'loss': 1.17494327, 'lr': 0, 'params': 106476, 'time_iter': 0.21917, 'accuracy': 0.56041, 'f1': 0.55942, 'accuracy-SBM': 0.56016, 'auc': 0.86166}
test: {'epoch': 26, 'time_epoch': 1.72795, 'loss': 1.17433297, 'lr': 0, 'params': 106476, 'time_iter': 0.21599, 'accuracy': 0.55933, 'f1': 0.55842, 'accuracy-SBM': 0.5591, 'auc': 0.86145}
> Epoch 26: took 33.2s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 27, 'time_epoch': 28.59498, 'eta': 628.7286, 'eta_hours': 0.17465, 'loss': 1.08790063, 'lr': 0.00051745, 'params': 106476, 'time_iter': 0.36196, 'accuracy': 0.59558, 'f1': 0.59558, 'accuracy-SBM': 0.59558, 'auc': 0.87852}
val: {'epoch': 27, 'time_epoch': 1.79175, 'loss': 1.26745175, 'lr': 0, 'params': 106476, 'time_iter': 0.22397, 'accuracy': 0.52193, 'f1': 0.51634, 'accuracy-SBM': 0.52271, 'auc': 0.84833}
test: {'epoch': 27, 'time_epoch': 1.72189, 'loss': 1.26330501, 'lr': 0, 'params': 106476, 'time_iter': 0.21524, 'accuracy': 0.52644, 'f1': 0.52143, 'accuracy-SBM': 0.52691, 'auc': 0.84854}
> Epoch 27: took 33.3s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 28, 'time_epoch': 28.79997, 'eta': 600.31035, 'eta_hours': 0.16675, 'loss': 1.08676254, 'lr': 0.00048255, 'params': 106476, 'time_iter': 0.36456, 'accuracy': 0.5961, 'f1': 0.59609, 'accuracy-SBM': 0.59609, 'auc': 0.8788}
val: {'epoch': 28, 'time_epoch': 1.76054, 'loss': 1.1859939, 'lr': 0, 'params': 106476, 'time_iter': 0.22007, 'accuracy': 0.55419, 'f1': 0.55077, 'accuracy-SBM': 0.55336, 'auc': 0.86103}
test: {'epoch': 28, 'time_epoch': 1.71325, 'loss': 1.18253283, 'lr': 0, 'params': 106476, 'time_iter': 0.21416, 'accuracy': 0.55708, 'f1': 0.55401, 'accuracy-SBM': 0.55657, 'auc': 0.86157}
> Epoch 28: took 33.5s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 29, 'time_epoch': 28.53549, 'eta': 571.69033, 'eta_hours': 0.1588, 'loss': 1.08527427, 'lr': 0.00044774, 'params': 106476, 'time_iter': 0.36121, 'accuracy': 0.59652, 'f1': 0.59652, 'accuracy-SBM': 0.59652, 'auc': 0.87915}
val: {'epoch': 29, 'time_epoch': 1.77122, 'loss': 1.24376103, 'lr': 0, 'params': 106476, 'time_iter': 0.2214, 'accuracy': 0.53088, 'f1': 0.52798, 'accuracy-SBM': 0.53079, 'auc': 0.84358}
test: {'epoch': 29, 'time_epoch': 1.74561, 'loss': 1.23956506, 'lr': 0, 'params': 106476, 'time_iter': 0.2182, 'accuracy': 0.53263, 'f1': 0.53021, 'accuracy-SBM': 0.5323, 'auc': 0.84396}
> Epoch 29: took 33.3s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 30, 'time_epoch': 28.4985, 'eta': 543.05309, 'eta_hours': 0.15085, 'loss': 1.08442907, 'lr': 0.00041318, 'params': 106476, 'time_iter': 0.36074, 'accuracy': 0.59705, 'f1': 0.59705, 'accuracy-SBM': 0.59705, 'auc': 0.87935}
val: {'epoch': 30, 'time_epoch': 1.77575, 'loss': 1.31714912, 'lr': 0, 'params': 106476, 'time_iter': 0.22197, 'accuracy': 0.50173, 'f1': 0.50027, 'accuracy-SBM': 0.50114, 'auc': 0.84923}
test: {'epoch': 30, 'time_epoch': 1.73146, 'loss': 1.31060099, 'lr': 0, 'params': 106476, 'time_iter': 0.21643, 'accuracy': 0.50439, 'f1': 0.50331, 'accuracy-SBM': 0.50418, 'auc': 0.84979}
> Epoch 30: took 33.2s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 31, 'time_epoch': 28.53827, 'eta': 514.4469, 'eta_hours': 0.1429, 'loss': 1.08254612, 'lr': 0.00037904, 'params': 106476, 'time_iter': 0.36124, 'accuracy': 0.59769, 'f1': 0.59769, 'accuracy-SBM': 0.59769, 'auc': 0.87978}
val: {'epoch': 31, 'time_epoch': 1.7849, 'loss': 1.19562151, 'lr': 0, 'params': 106476, 'time_iter': 0.22311, 'accuracy': 0.54997, 'f1': 0.54805, 'accuracy-SBM': 0.55038, 'auc': 0.85888}
test: {'epoch': 31, 'time_epoch': 1.73217, 'loss': 1.18860138, 'lr': 0, 'params': 106476, 'time_iter': 0.21652, 'accuracy': 0.55385, 'f1': 0.55181, 'accuracy-SBM': 0.55354, 'auc': 0.86011}
> Epoch 31: took 33.3s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 32, 'time_epoch': 28.50449, 'eta': 485.82742, 'eta_hours': 0.13495, 'loss': 1.08139554, 'lr': 0.00034549, 'params': 106476, 'time_iter': 0.36082, 'accuracy': 0.59828, 'f1': 0.59828, 'accuracy-SBM': 0.59828, 'auc': 0.88005}
val: {'epoch': 32, 'time_epoch': 1.74998, 'loss': 1.25005596, 'lr': 0, 'params': 106476, 'time_iter': 0.21875, 'accuracy': 0.53118, 'f1': 0.52201, 'accuracy-SBM': 0.53257, 'auc': 0.84985}
test: {'epoch': 32, 'time_epoch': 1.74456, 'loss': 1.24481551, 'lr': 0, 'params': 106476, 'time_iter': 0.21807, 'accuracy': 0.53296, 'f1': 0.5235, 'accuracy-SBM': 0.53328, 'auc': 0.85085}
> Epoch 32: took 33.2s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 33, 'time_epoch': 28.515, 'eta': 457.21965, 'eta_hours': 0.12701, 'loss': 1.0806463, 'lr': 0.0003127, 'params': 106476, 'time_iter': 0.36095, 'accuracy': 0.59845, 'f1': 0.59845, 'accuracy-SBM': 0.59845, 'auc': 0.88023}
val: {'epoch': 33, 'time_epoch': 1.77099, 'loss': 1.18496485, 'lr': 0, 'params': 106476, 'time_iter': 0.22137, 'accuracy': 0.55866, 'f1': 0.55789, 'accuracy-SBM': 0.55806, 'auc': 0.86169}
test: {'epoch': 33, 'time_epoch': 1.73027, 'loss': 1.18383297, 'lr': 0, 'params': 106476, 'time_iter': 0.21628, 'accuracy': 0.55787, 'f1': 0.55767, 'accuracy-SBM': 0.55796, 'auc': 0.86193}
> Epoch 33: took 33.2s (avg 33.3s) | Best so far: epoch 26	train loss: 1.0893 train_accuracy-SBM: 0.5952	val loss: 1.1749 val_accuracy-SBM: 0.5602	test loss: 1.1743 test_accuracy-SBM: 0.5591
train: {'epoch': 34, 'time_epoch': 27.39135, 'eta': 428.13562, 'eta_hours': 0.11893, 'loss': 1.07941828, 'lr': 0.00028081, 'params': 106476, 'time_iter': 0.34673, 'accuracy': 0.59885, 'f1': 0.59885, 'accuracy-SBM': 0.59885, 'auc': 0.88052}
val: {'epoch': 34, 'time_epoch': 1.68287, 'loss': 1.17596653, 'lr': 0, 'params': 106476, 'time_iter': 0.21036, 'accuracy': 0.56048, 'f1': 0.55925, 'accuracy-SBM': 0.56052, 'auc': 0.86269}
test: {'epoch': 34, 'time_epoch': 1.69249, 'loss': 1.16820675, 'lr': 0, 'params': 106476, 'time_iter': 0.21156, 'accuracy': 0.56322, 'f1': 0.56211, 'accuracy-SBM': 0.56358, 'auc': 0.86444}
> Epoch 34: took 31.9s (avg 33.3s) | Best so far: epoch 34	train loss: 1.0794 train_accuracy-SBM: 0.5988	val loss: 1.1760 val_accuracy-SBM: 0.5605	test loss: 1.1682 test_accuracy-SBM: 0.5636
train: {'epoch': 35, 'time_epoch': 27.41453, 'eta': 399.15463, 'eta_hours': 0.11088, 'loss': 1.07833395, 'lr': 0.00025, 'params': 106476, 'time_iter': 0.34702, 'accuracy': 0.59919, 'f1': 0.59919, 'accuracy-SBM': 0.59919, 'auc': 0.88078}
val: {'epoch': 35, 'time_epoch': 1.70516, 'loss': 1.12986615, 'lr': 0, 'params': 106476, 'time_iter': 0.21314, 'accuracy': 0.57706, 'f1': 0.57595, 'accuracy-SBM': 0.57678, 'auc': 0.87194}
test: {'epoch': 35, 'time_epoch': 1.66103, 'loss': 1.12926553, 'lr': 0, 'params': 106476, 'time_iter': 0.20763, 'accuracy': 0.57744, 'f1': 0.57641, 'accuracy-SBM': 0.57756, 'auc': 0.87229}
> Epoch 35: took 32.0s (avg 33.2s) | Best so far: epoch 35	train loss: 1.0783 train_accuracy-SBM: 0.5992	val loss: 1.1299 val_accuracy-SBM: 0.5768	test loss: 1.1293 test_accuracy-SBM: 0.5776
train: {'epoch': 36, 'time_epoch': 27.26972, 'eta': 370.20745, 'eta_hours': 0.10284, 'loss': 1.07754474, 'lr': 0.0002204, 'params': 106476, 'time_iter': 0.34519, 'accuracy': 0.59958, 'f1': 0.59958, 'accuracy-SBM': 0.59958, 'auc': 0.88095}
val: {'epoch': 36, 'time_epoch': 1.7118, 'loss': 1.11340707, 'lr': 0, 'params': 106476, 'time_iter': 0.21397, 'accuracy': 0.58387, 'f1': 0.58381, 'accuracy-SBM': 0.58383, 'auc': 0.87323}
test: {'epoch': 36, 'time_epoch': 1.65399, 'loss': 1.11233871, 'lr': 0, 'params': 106476, 'time_iter': 0.20675, 'accuracy': 0.58547, 'f1': 0.58546, 'accuracy-SBM': 0.58555, 'auc': 0.87354}
> Epoch 36: took 31.8s (avg 33.2s) | Best so far: epoch 36	train loss: 1.0775 train_accuracy-SBM: 0.5996	val loss: 1.1134 val_accuracy-SBM: 0.5838	test loss: 1.1123 test_accuracy-SBM: 0.5856
train: {'epoch': 37, 'time_epoch': 27.31371, 'eta': 341.36244, 'eta_hours': 0.09482, 'loss': 1.07662385, 'lr': 0.00019217, 'params': 106476, 'time_iter': 0.34574, 'accuracy': 0.59997, 'f1': 0.59996, 'accuracy-SBM': 0.59997, 'auc': 0.88116}
val: {'epoch': 37, 'time_epoch': 1.67575, 'loss': 1.19300137, 'lr': 0, 'params': 106476, 'time_iter': 0.20947, 'accuracy': 0.5518, 'f1': 0.55043, 'accuracy-SBM': 0.55243, 'auc': 0.85995}
test: {'epoch': 37, 'time_epoch': 1.64919, 'loss': 1.18860418, 'lr': 0, 'params': 106476, 'time_iter': 0.20615, 'accuracy': 0.5527, 'f1': 0.55141, 'accuracy-SBM': 0.55286, 'auc': 0.86019}
> Epoch 37: took 31.8s (avg 33.1s) | Best so far: epoch 36	train loss: 1.0775 train_accuracy-SBM: 0.5996	val loss: 1.1134 val_accuracy-SBM: 0.5838	test loss: 1.1123 test_accuracy-SBM: 0.5856
train: {'epoch': 38, 'time_epoch': 27.30322, 'eta': 312.593, 'eta_hours': 0.08683, 'loss': 1.07597488, 'lr': 0.00016543, 'params': 106476, 'time_iter': 0.34561, 'accuracy': 0.60021, 'f1': 0.60021, 'accuracy-SBM': 0.60021, 'auc': 0.88132}
val: {'epoch': 38, 'time_epoch': 1.68251, 'loss': 1.16933065, 'lr': 0, 'params': 106476, 'time_iter': 0.21031, 'accuracy': 0.56345, 'f1': 0.56075, 'accuracy-SBM': 0.56335, 'auc': 0.8635}
test: {'epoch': 38, 'time_epoch': 1.67003, 'loss': 1.16332673, 'lr': 0, 'params': 106476, 'time_iter': 0.20875, 'accuracy': 0.56643, 'f1': 0.56372, 'accuracy-SBM': 0.5661, 'auc': 0.86466}
> Epoch 38: took 31.8s (avg 33.1s) | Best so far: epoch 36	train loss: 1.0775 train_accuracy-SBM: 0.5996	val loss: 1.1134 val_accuracy-SBM: 0.5838	test loss: 1.1123 test_accuracy-SBM: 0.5856
train: {'epoch': 39, 'time_epoch': 27.46127, 'eta': 283.93639, 'eta_hours': 0.07887, 'loss': 1.07498659, 'lr': 0.00014033, 'params': 106476, 'time_iter': 0.34761, 'accuracy': 0.60073, 'f1': 0.60073, 'accuracy-SBM': 0.60073, 'auc': 0.88154}
val: {'epoch': 39, 'time_epoch': 1.68843, 'loss': 1.12898738, 'lr': 0, 'params': 106476, 'time_iter': 0.21105, 'accuracy': 0.57991, 'f1': 0.57925, 'accuracy-SBM': 0.57974, 'auc': 0.87049}
test: {'epoch': 39, 'time_epoch': 1.66237, 'loss': 1.12544879, 'lr': 0, 'params': 106476, 'time_iter': 0.2078, 'accuracy': 0.58084, 'f1': 0.58018, 'accuracy-SBM': 0.58077, 'auc': 0.87135}
> Epoch 39: took 32.0s (avg 33.1s) | Best so far: epoch 36	train loss: 1.0775 train_accuracy-SBM: 0.5996	val loss: 1.1134 val_accuracy-SBM: 0.5838	test loss: 1.1123 test_accuracy-SBM: 0.5856
train: {'epoch': 40, 'time_epoch': 27.37384, 'eta': 255.31889, 'eta_hours': 0.07092, 'loss': 1.07423722, 'lr': 0.00011698, 'params': 106476, 'time_iter': 0.3465, 'accuracy': 0.60083, 'f1': 0.60083, 'accuracy-SBM': 0.60083, 'auc': 0.88172}
val: {'epoch': 40, 'time_epoch': 1.69593, 'loss': 1.12226948, 'lr': 0, 'params': 106476, 'time_iter': 0.21199, 'accuracy': 0.58286, 'f1': 0.58258, 'accuracy-SBM': 0.58296, 'auc': 0.87278}
test: {'epoch': 40, 'time_epoch': 1.64841, 'loss': 1.11916716, 'lr': 0, 'params': 106476, 'time_iter': 0.20605, 'accuracy': 0.58392, 'f1': 0.58385, 'accuracy-SBM': 0.58424, 'auc': 0.87364}
> Epoch 40: took 31.9s (avg 33.1s) | Best so far: epoch 36	train loss: 1.0775 train_accuracy-SBM: 0.5996	val loss: 1.1134 val_accuracy-SBM: 0.5838	test loss: 1.1123 test_accuracy-SBM: 0.5856
train: {'epoch': 41, 'time_epoch': 27.36048, 'eta': 226.75807, 'eta_hours': 0.06299, 'loss': 1.07348246, 'lr': 9.549e-05, 'params': 106476, 'time_iter': 0.34634, 'accuracy': 0.60135, 'f1': 0.60135, 'accuracy-SBM': 0.60135, 'auc': 0.88188}
val: {'epoch': 41, 'time_epoch': 1.69079, 'loss': 1.10424123, 'lr': 0, 'params': 106476, 'time_iter': 0.21135, 'accuracy': 0.58861, 'f1': 0.58835, 'accuracy-SBM': 0.58853, 'auc': 0.87503}
test: {'epoch': 41, 'time_epoch': 1.6561, 'loss': 1.10115242, 'lr': 0, 'params': 106476, 'time_iter': 0.20701, 'accuracy': 0.59074, 'f1': 0.5906, 'accuracy-SBM': 0.59064, 'auc': 0.87563}
> Epoch 41: took 31.9s (avg 33.0s) | Best so far: epoch 41	train loss: 1.0735 train_accuracy-SBM: 0.6014	val loss: 1.1042 val_accuracy-SBM: 0.5885	test loss: 1.1012 test_accuracy-SBM: 0.5906
train: {'epoch': 42, 'time_epoch': 27.40294, 'eta': 198.25999, 'eta_hours': 0.05507, 'loss': 1.07323502, 'lr': 7.598e-05, 'params': 106476, 'time_iter': 0.34687, 'accuracy': 0.60136, 'f1': 0.60136, 'accuracy-SBM': 0.60136, 'auc': 0.88194}
val: {'epoch': 42, 'time_epoch': 1.68427, 'loss': 1.10123212, 'lr': 0, 'params': 106476, 'time_iter': 0.21053, 'accuracy': 0.5893, 'f1': 0.58916, 'accuracy-SBM': 0.58943, 'auc': 0.87595}
test: {'epoch': 42, 'time_epoch': 1.66899, 'loss': 1.09797751, 'lr': 0, 'params': 106476, 'time_iter': 0.20862, 'accuracy': 0.59181, 'f1': 0.5917, 'accuracy-SBM': 0.59176, 'auc': 0.87658}
> Epoch 42: took 31.9s (avg 33.0s) | Best so far: epoch 42	train loss: 1.0732 train_accuracy-SBM: 0.6014	val loss: 1.1012 val_accuracy-SBM: 0.5894	test loss: 1.0980 test_accuracy-SBM: 0.5918
train: {'epoch': 43, 'time_epoch': 27.39967, 'eta': 169.81125, 'eta_hours': 0.04717, 'loss': 1.07271794, 'lr': 5.853e-05, 'params': 106476, 'time_iter': 0.34683, 'accuracy': 0.60157, 'f1': 0.60157, 'accuracy-SBM': 0.60157, 'auc': 0.88206}
val: {'epoch': 43, 'time_epoch': 1.68386, 'loss': 1.10238316, 'lr': 0, 'params': 106476, 'time_iter': 0.21048, 'accuracy': 0.59079, 'f1': 0.59063, 'accuracy-SBM': 0.59053, 'auc': 0.87533}
test: {'epoch': 43, 'time_epoch': 1.64778, 'loss': 1.09904073, 'lr': 0, 'params': 106476, 'time_iter': 0.20597, 'accuracy': 0.59084, 'f1': 0.59086, 'accuracy-SBM': 0.59083, 'auc': 0.87614}
> Epoch 43: took 31.9s (avg 33.0s) | Best so far: epoch 43	train loss: 1.0727 train_accuracy-SBM: 0.6016	val loss: 1.1024 val_accuracy-SBM: 0.5905	test loss: 1.0990 test_accuracy-SBM: 0.5908
train: {'epoch': 44, 'time_epoch': 26.98521, 'eta': 141.36308, 'eta_hours': 0.03927, 'loss': 1.07229788, 'lr': 4.323e-05, 'params': 106476, 'time_iter': 0.34158, 'accuracy': 0.60167, 'f1': 0.60167, 'accuracy-SBM': 0.60167, 'auc': 0.88217}
val: {'epoch': 44, 'time_epoch': 1.64573, 'loss': 1.10150452, 'lr': 0, 'params': 106476, 'time_iter': 0.20572, 'accuracy': 0.58934, 'f1': 0.58919, 'accuracy-SBM': 0.5894, 'auc': 0.87577}
test: {'epoch': 44, 'time_epoch': 1.63484, 'loss': 1.09780225, 'lr': 0, 'params': 106476, 'time_iter': 0.20435, 'accuracy': 0.59089, 'f1': 0.59073, 'accuracy-SBM': 0.59081, 'auc': 0.87651}
> Epoch 44: took 31.4s (avg 32.9s) | Best so far: epoch 43	train loss: 1.0727 train_accuracy-SBM: 0.6016	val loss: 1.1024 val_accuracy-SBM: 0.5905	test loss: 1.0990 test_accuracy-SBM: 0.5908
train: {'epoch': 45, 'time_epoch': 26.6251, 'eta': 112.9472, 'eta_hours': 0.03137, 'loss': 1.07221006, 'lr': 3.015e-05, 'params': 106476, 'time_iter': 0.33703, 'accuracy': 0.60173, 'f1': 0.60173, 'accuracy-SBM': 0.60173, 'auc': 0.88218}
val: {'epoch': 45, 'time_epoch': 1.63576, 'loss': 1.10263409, 'lr': 0, 'params': 106476, 'time_iter': 0.20447, 'accuracy': 0.59083, 'f1': 0.5907, 'accuracy-SBM': 0.59067, 'auc': 0.87543}
test: {'epoch': 45, 'time_epoch': 1.62221, 'loss': 1.09934215, 'lr': 0, 'params': 106476, 'time_iter': 0.20278, 'accuracy': 0.59157, 'f1': 0.59154, 'accuracy-SBM': 0.59159, 'auc': 0.87628}
> Epoch 45: took 31.0s (avg 32.9s) | Best so far: epoch 45	train loss: 1.0722 train_accuracy-SBM: 0.6017	val loss: 1.1026 val_accuracy-SBM: 0.5907	test loss: 1.0993 test_accuracy-SBM: 0.5916
train: {'epoch': 46, 'time_epoch': 26.51928, 'eta': 84.60077, 'eta_hours': 0.0235, 'loss': 1.07175373, 'lr': 1.937e-05, 'params': 106476, 'time_iter': 0.33569, 'accuracy': 0.60192, 'f1': 0.60192, 'accuracy-SBM': 0.60192, 'auc': 0.88228}
val: {'epoch': 46, 'time_epoch': 1.62565, 'loss': 1.09654535, 'lr': 0, 'params': 106476, 'time_iter': 0.20321, 'accuracy': 0.59155, 'f1': 0.59154, 'accuracy-SBM': 0.59162, 'auc': 0.87659}
test: {'epoch': 46, 'time_epoch': 1.59616, 'loss': 1.09367662, 'lr': 0, 'params': 106476, 'time_iter': 0.19952, 'accuracy': 0.59301, 'f1': 0.59303, 'accuracy-SBM': 0.59305, 'auc': 0.87727}
> Epoch 46: took 30.9s (avg 32.9s) | Best so far: epoch 46	train loss: 1.0718 train_accuracy-SBM: 0.6019	val loss: 1.0965 val_accuracy-SBM: 0.5916	test loss: 1.0937 test_accuracy-SBM: 0.5930
train: {'epoch': 47, 'time_epoch': 26.88922, 'eta': 56.34589, 'eta_hours': 0.01565, 'loss': 1.07134201, 'lr': 1.093e-05, 'params': 106476, 'time_iter': 0.34037, 'accuracy': 0.60183, 'f1': 0.60183, 'accuracy-SBM': 0.60183, 'auc': 0.88238}
val: {'epoch': 47, 'time_epoch': 1.65845, 'loss': 1.09572451, 'lr': 0, 'params': 106476, 'time_iter': 0.20731, 'accuracy': 0.59237, 'f1': 0.59231, 'accuracy-SBM': 0.59234, 'auc': 0.87669}
test: {'epoch': 47, 'time_epoch': 1.63457, 'loss': 1.09197449, 'lr': 0, 'params': 106476, 'time_iter': 0.20432, 'accuracy': 0.59342, 'f1': 0.59341, 'accuracy-SBM': 0.59341, 'auc': 0.87756}
> Epoch 47: took 31.3s (avg 32.8s) | Best so far: epoch 47	train loss: 1.0713 train_accuracy-SBM: 0.6018	val loss: 1.0957 val_accuracy-SBM: 0.5923	test loss: 1.0920 test_accuracy-SBM: 0.5934
train: {'epoch': 48, 'time_epoch': 26.7368, 'eta': 28.14363, 'eta_hours': 0.00782, 'loss': 1.0711894, 'lr': 4.87e-06, 'params': 106476, 'time_iter': 0.33844, 'accuracy': 0.60197, 'f1': 0.60197, 'accuracy-SBM': 0.60197, 'auc': 0.88241}
val: {'epoch': 48, 'time_epoch': 1.64485, 'loss': 1.09508653, 'lr': 0, 'params': 106476, 'time_iter': 0.20561, 'accuracy': 0.59301, 'f1': 0.59294, 'accuracy-SBM': 0.59296, 'auc': 0.87679}
test: {'epoch': 48, 'time_epoch': 1.61204, 'loss': 1.09197994, 'lr': 0, 'params': 106476, 'time_iter': 0.20151, 'accuracy': 0.59321, 'f1': 0.59319, 'accuracy-SBM': 0.59319, 'auc': 0.87752}
> Epoch 48: took 31.1s (avg 32.8s) | Best so far: epoch 48	train loss: 1.0712 train_accuracy-SBM: 0.6020	val loss: 1.0951 val_accuracy-SBM: 0.5930	test loss: 1.0920 test_accuracy-SBM: 0.5932
train: {'epoch': 49, 'time_epoch': 26.60482, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 1.07122309, 'lr': 1.22e-06, 'params': 106476, 'time_iter': 0.33677, 'accuracy': 0.60235, 'f1': 0.60234, 'accuracy-SBM': 0.60235, 'auc': 0.88241}
val: {'epoch': 49, 'time_epoch': 1.65867, 'loss': 1.09476223, 'lr': 0, 'params': 106476, 'time_iter': 0.20733, 'accuracy': 0.59311, 'f1': 0.59303, 'accuracy-SBM': 0.59304, 'auc': 0.87685}
test: {'epoch': 49, 'time_epoch': 1.65312, 'loss': 1.09200831, 'lr': 0, 'params': 106476, 'time_iter': 0.20664, 'accuracy': 0.59316, 'f1': 0.59314, 'accuracy-SBM': 0.59314, 'auc': 0.87752}
> Epoch 49: took 31.0s (avg 32.8s) | Best so far: epoch 49	train loss: 1.0712 train_accuracy-SBM: 0.6024	val loss: 1.0948 val_accuracy-SBM: 0.5930	test loss: 1.0920 test_accuracy-SBM: 0.5931
Avg time per epoch: 32.75s
Total train loop time: 0.45h
Task done, results saved in tests/results/cluster/gatedgcn-100k/2025-05-13/22-20-57-778547-cluster-gatedgcn-100k/11
Failed when trying to aggregate multiple runs: Tensorboard support requires `tensorboardX`.
[*] All done: 2025-05-13 22:48:23.821428
