[*] Run ID 11: seed=11, split_index=0
    Starting now: 2025-05-12 22:08:25.523042
[*] Loaded dataset 'CLUSTER' from 'PyG-GNNBenchmarkDataset':
  Data(x=[1406436, 7], edge_index=[2, 51620680], y=[1406436])
  undirected: True
  num graphs: 12000
  avg num_nodes/graph: 117
  num node features: 7
  num edge features: 0
  num classes: 6
Precomputing Positional Encoding statistics: ['MagLapPE'] for all graphs...
  ...estimated to be undirected: True
Done! Took 00:01:52.13
GraphGymModule(
  (model): S2GNN(
    (encoder): FeatureEncoder(
      (node_encoder): LinearNodeEncoder(
        (encoder): Linear(in_features=7, out_features=152, bias=True)
      )
    )
    (gnn_layers): Sequential(
      (0): GATConvGNNLayer(
        (pre_dropout): Dropout(p=0.0, inplace=False)
        (conv): GATConv(152, 19, heads=8)
        (bn): BatchNorm1d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): GELU(approximate='none')
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (1): GATConvGNNLayer(
        (conv): GATConv(152, 19, heads=8)
        (bn): BatchNorm1d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): GELU(approximate='none')
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (2): FeatureBatchSpectralLayer(
        (filter): FilterEncoder(
          (filter): BasisFunctionsLayer(
            (distance_expansion): GaussianSmearing()
            (linear): Sequential(
              (0): Linear(in_features=50, out_features=152, bias=True)
            )
          )
        )
        (feature_transform): SpecFeatureTransformLayer(
          (layer_real): GLULayer(
            (lin1): Linear(in_features=152, out_features=152, bias=True)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (window): Window()
      )
      (3): GATConvGNNLayer(
        (conv): GATConv(152, 19, heads=8)
        (bn): BatchNorm1d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): GELU(approximate='none')
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (4): GATConvGNNLayer(
        (conv): GATConv(152, 19, heads=8)
        (bn): BatchNorm1d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): GELU(approximate='none')
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (5): FeatureBatchSpectralLayer(
        (filter): FilterEncoder(
          (filter): BasisFunctionsLayer(
            (distance_expansion): GaussianSmearing()
            (linear): Sequential(
              (0): Linear(in_features=50, out_features=152, bias=True)
            )
          )
        )
        (feature_transform): SpecFeatureTransformLayer(
          (layer_real): GLULayer(
            (lin1): Linear(in_features=152, out_features=152, bias=True)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (window): Window()
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (mlp): Sequential(
        (0): Dropout(p=0.1, inplace=False)
        (1): Linear(in_features=152, out_features=152, bias=True)
        (2): GELU(approximate='none')
        (3): Dropout(p=0.1, inplace=False)
        (4): Linear(in_features=152, out_features=6, bias=True)
      )
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  arxiv_year:
    num_split: 0
    with_ogbn_arxiv_labels: False
  associative_recall:
    n_graphs: (25000, 500, 500)
    num_keys: 1
    num_vocab: 30
    precalc_eigdec_k: 10
    test_n_nodes: (1000, 1200)
    train_n_nodes: (20, 1000)
    valid_n_nodes: (20, 1000)
  cache_load: False
  cache_save: False
  custom_cluster:
    gmm_cluster_from_posterior: True
    gmm_dim: 2
    gmm_edges_max: 10
    gmm_edges_min: 1
    gmm_range_clusters: 10
    gmm_std_clusters: 2
    graph_type: gmm
    n_clusters: 6
    n_graphs: (10000, 1000, 1000)
    random_p: 0.55
    random_q: 0.25
    size_max: 35
    size_min: 5
  dir: ./datasets
  edge_dim: 128
  edge_encoder: False
  edge_encoder_bn: True
  edge_encoder_name: Bond
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: PyG-GNNBenchmarkDataset
  label_column: none
  label_table: none
  location: local
  name: CLUSTER
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LinearNode
  node_encoder_num_types: 0
  ogbn_arxiv:
    mask_rate: 0.5
    use_labels: True
  over_squashing:
    gen_mode: full
    n_classes: 5
    n_graphs: (5000, 500, 5000)
    test_n_nodes: (52, 100)
    topology: ring_lollipop
    train_n_nodes: (4, 50)
    valid_n_nodes: (4, 50)
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  source_dist:
    n_graphs: (50000, 2500, 2500)
    p_add_edges_from_tree: 0
    test_n_nodes: (1100, 1200)
    train_n_nodes: (500, 1000)
    valid_n_nodes: (1000, 1100)
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  tpu_graphs:
    config_node_readout: False
    custom: False
    drop_high_deg_sinks: False
    drop_high_deg_sources: False
    drop_last_node_above_deg: -1
    encoder_factor: 100.0
    include_valid_in_train: False
    normalize: False
    search: ['random']
    source: ['nlp']
    subsample: 500
    tpu_task: layout
  transductive: False
  transform: none
  tu_simple: True
device: cuda
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: gelu
  adj_norm: dir
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: False
  batchnorm_post_mp: False
  clear_feature: True
  dim_inner: 152
  dir_aggr: cat
  dropout: 0.1
  gatconv:
    attn_dropout: 0.0
    backend: PyG
    feat_dropout: 0.0
    negative_slope: 0.2
    norm: True
    num_heads: 8
    pre_dropout: 0.0
    with_linear: False
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_skip: []
  layer_type: gatconv
  layernorm_post_mp: False
  layers_mp: 4
  layers_post_mp: 2
  layers_pre_mp: 0
  make_undirected: True
  msg_direction: single
  node_dropout: 0.0
  normalize_adj: False
  residual: True
  self_msg: concat
  skip_every: 1
  spectral:
    basis_bottleneck: 1.0
    basis_init_type: default
    basis_num_gaussians: 50
    combine_with_spatial: None
    combine_with_spatial_norm: True
    dropout: -1.0
    eigv_scale: -1
    feature_transform: glu
    filter_encoder: basis
    filter_layers: 1
    filter_value_trans: None
    filter_variant: None
    frequency_cutoff: 1.3
    layer_skip: [0, 2]
    learnable_norm: True
    learnable_norm_init: 0
    mlp_layers_filter_encoder: 2
    num_heads_filter_encoder: -1
    readout: None
    readout_residual: False
    readout_sepnorm: False
    real_imag_x_merge: None
    residual: True
    window: tukey
  stage_type: stack
  use_edge_attr: False
gpu_mem: False
gt:
  attn_dropout: 0.0
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  dim_hidden: 64
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: SANLayer
  layers: 3
  n_heads: 8
  pna_degrees: []
  residual: True
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy-SBM
model:
  edge_decoding: dot
  graph_pooling: add
  list_mle_divisor: 250
  loss_fun: weighted_cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: s2gnn
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.001
  batch_accumulation: 1
  clip_grad_norm: True
  last_layer_no_wd: False
  lr_decay: 0.1
  max_epoch: 50
  min_lr: 0.0
  model_averaging: None
  model_averaging_start: 0
  momentum: 0.9
  num_warmup_epochs: 5
  optimizer: adamW
  quasi_alternating: -1
  reduce_factor: 0.1
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  stop_patience: 1000
  weight_decay: 0.0
out_dir: tests/results/cluster/gat-s2gnn-100k/2025-05-12/22-08-25-327497-cluster-gat-s2gnn-100k
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_MagLapPE:
  dim_pe: 0
  drop_trailing_repeated: False
  enable: True
  kwargs:
    
  laplacian_norm: sym
  largest_connected_component: False
  layers: 3
  max_freqs: 50
  model: none
  n_heads: 4
  pass_as_var: False
  positional_encoding: False
  post_layers: 0
  precompute: False
  q: 0.0
  raw_norm_type: none
  sparse: True
  which: SA
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: False
print: both
round: 5
run_dir: tests/results/cluster/gat-s2gnn-100k/2025-05-12/22-08-25-327497-cluster-gat-s2gnn-100k/11
run_id: 11
run_multiple_splits: []
seed: 11
share:
  dim_in: 7
  dim_out: 6
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: False
train:
  auto_resume: False
  batch_size: 128
  ckpt_best: True
  ckpt_clean: True
  ckpt_data_attrs: ['y', 'pred', 'batch']
  ckpt_data_splits: ['val', 'test']
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  num_sample_configs: 16
  radius: extend
  sample_node: False
  sampler: full_batch
  scale_num_sample_configs: True
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  num_sample_batch: 100
  num_sample_configs: 1000
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: tum_i26
  name: 
  project: cluster
  tags: 
  use: False
Num parameters: 183470
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 203.93292, 'eta': 9992.713, 'eta_hours': 2.77575, 'loss': 1.86558592, 'lr': 0.0, 'params': 183470, 'time_iter': 2.58143, 'accuracy': 0.14294, 'f1': 0.11098, 'accuracy-SBM': 0.14294, 'auc': 0.4609}
...computing epoch stats took: 0.46s
val: {'epoch': 0, 'time_epoch': 19.76864, 'loss': 1.93134134, 'lr': 0, 'params': 183470, 'time_iter': 2.47108, 'accuracy': 0.15228, 'f1': 0.09913, 'accuracy-SBM': 0.15262, 'auc': 0.47809}
...computing epoch stats took: 0.24s
test: {'epoch': 0, 'time_epoch': 20.41487, 'loss': 1.92723904, 'lr': 0, 'params': 183470, 'time_iter': 2.55186, 'accuracy': 0.15198, 'f1': 0.09961, 'accuracy-SBM': 0.15149, 'auc': 0.48081}
...computing epoch stats took: 0.22s
> Epoch 0: took 245.1s (avg 245.1s) | Best so far: epoch 0	train loss: 1.8656 train_accuracy-SBM: 0.1429	val loss: 1.9313 val_accuracy-SBM: 0.1526	test loss: 1.9272 test_accuracy-SBM: 0.1515
train: {'epoch': 1, 'time_epoch': 216.40379, 'eta': 10088.08099, 'eta_hours': 2.80224, 'loss': 1.51465117, 'lr': 0.0002, 'params': 183470, 'time_iter': 2.73929, 'accuracy': 0.407, 'f1': 0.40582, 'accuracy-SBM': 0.40702, 'auc': 0.74445}
...computing epoch stats took: 0.38s
val: {'epoch': 1, 'time_epoch': 17.57725, 'loss': 12.96898482, 'lr': 0, 'params': 183470, 'time_iter': 2.19716, 'accuracy': 0.19188, 'f1': 0.09101, 'accuracy-SBM': 0.19061, 'auc': 0.71248}
...computing epoch stats took: 0.20s
test: {'epoch': 1, 'time_epoch': 17.40431, 'loss': 12.91493677, 'lr': 0, 'params': 183470, 'time_iter': 2.17554, 'accuracy': 0.19735, 'f1': 0.09735, 'accuracy-SBM': 0.19496, 'auc': 0.71506}
...computing epoch stats took: 0.19s
> Epoch 1: took 252.2s (avg 248.6s) | Best so far: epoch 1	train loss: 1.5147 train_accuracy-SBM: 0.4070	val loss: 12.9690 val_accuracy-SBM: 0.1906	test loss: 12.9149 test_accuracy-SBM: 0.1950
train: {'epoch': 2, 'time_epoch': 202.95452, 'eta': 9764.89585, 'eta_hours': 2.71247, 'loss': 1.1217019, 'lr': 0.0004, 'params': 183470, 'time_iter': 2.56904, 'accuracy': 0.58579, 'f1': 0.58578, 'accuracy-SBM': 0.58579, 'auc': 0.871}
...computing epoch stats took: 0.36s
val: {'epoch': 2, 'time_epoch': 18.89027, 'loss': 5.37961227, 'lr': 0, 'params': 183470, 'time_iter': 2.36128, 'accuracy': 0.33093, 'f1': 0.3007, 'accuracy-SBM': 0.33127, 'auc': 0.73665}
...computing epoch stats took: 0.21s
test: {'epoch': 2, 'time_epoch': 18.36422, 'loss': 5.32088413, 'lr': 0, 'params': 183470, 'time_iter': 2.29553, 'accuracy': 0.33406, 'f1': 0.303, 'accuracy-SBM': 0.33495, 'auc': 0.74322}
...computing epoch stats took: 0.17s
> Epoch 2: took 241.0s (avg 246.1s) | Best so far: epoch 2	train loss: 1.1217 train_accuracy-SBM: 0.5858	val loss: 5.3796 val_accuracy-SBM: 0.3313	test loss: 5.3209 test_accuracy-SBM: 0.3350
train: {'epoch': 3, 'time_epoch': 192.87236, 'eta': 9385.88117, 'eta_hours': 2.60719, 'loss': 1.0087096, 'lr': 0.0006, 'params': 183470, 'time_iter': 2.44142, 'accuracy': 0.62762, 'f1': 0.62762, 'accuracy-SBM': 0.62762, 'auc': 0.89661}
val: {'epoch': 3, 'time_epoch': 15.74129, 'loss': 2.58757399, 'lr': 0, 'params': 183470, 'time_iter': 1.96766, 'accuracy': 0.43041, 'f1': 0.42122, 'accuracy-SBM': 0.42829, 'auc': 0.80071}
test: {'epoch': 3, 'time_epoch': 14.18841, 'loss': 2.5788151, 'lr': 0, 'params': 183470, 'time_iter': 1.77355, 'accuracy': 0.43404, 'f1': 0.42684, 'accuracy-SBM': 0.43405, 'auc': 0.80278}
> Epoch 3: took 223.6s (avg 240.4s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 4, 'time_epoch': 190.53475, 'eta': 9060.28501, 'eta_hours': 2.51675, 'loss': 0.96581158, 'lr': 0.0008, 'params': 183470, 'time_iter': 2.41183, 'accuracy': 0.64364, 'f1': 0.64364, 'accuracy-SBM': 0.64364, 'auc': 0.90542}
val: {'epoch': 4, 'time_epoch': 17.68295, 'loss': 13.83876505, 'lr': 0, 'params': 183470, 'time_iter': 2.21037, 'accuracy': 0.23603, 'f1': 0.14883, 'accuracy-SBM': 0.23547, 'auc': 0.65107}
test: {'epoch': 4, 'time_epoch': 17.45292, 'loss': 13.55228508, 'lr': 0, 'params': 183470, 'time_iter': 2.18161, 'accuracy': 0.24158, 'f1': 0.15373, 'accuracy-SBM': 0.23971, 'auc': 0.65323}
> Epoch 4: took 226.7s (avg 237.7s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 5, 'time_epoch': 192.50518, 'eta': 8794.15908, 'eta_hours': 2.44282, 'loss': 0.91662595, 'lr': 0.001, 'params': 183470, 'time_iter': 2.43677, 'accuracy': 0.66231, 'f1': 0.66231, 'accuracy-SBM': 0.66231, 'auc': 0.91501}
val: {'epoch': 5, 'time_epoch': 18.82451, 'loss': 18.93346265, 'lr': 0, 'params': 183470, 'time_iter': 2.35306, 'accuracy': 0.17281, 'f1': 0.08623, 'accuracy-SBM': 0.17447, 'auc': 0.53788}
test: {'epoch': 5, 'time_epoch': 17.67581, 'loss': 18.93086547, 'lr': 0, 'params': 183470, 'time_iter': 2.20948, 'accuracy': 0.17354, 'f1': 0.08888, 'accuracy-SBM': 0.17452, 'auc': 0.53975}
> Epoch 5: took 229.8s (avg 236.4s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 6, 'time_epoch': 200.7944, 'eta': 8599.98719, 'eta_hours': 2.38889, 'loss': 0.87271573, 'lr': 0.00099878, 'params': 183470, 'time_iter': 2.5417, 'accuracy': 0.67959, 'f1': 0.67959, 'accuracy-SBM': 0.67959, 'auc': 0.92308}
val: {'epoch': 6, 'time_epoch': 18.78029, 'loss': 3.35534713, 'lr': 0, 'params': 183470, 'time_iter': 2.34754, 'accuracy': 0.28299, 'f1': 0.20546, 'accuracy-SBM': 0.28414, 'auc': 0.6108}
test: {'epoch': 6, 'time_epoch': 18.48796, 'loss': 3.35559729, 'lr': 0, 'params': 183470, 'time_iter': 2.31099, 'accuracy': 0.28766, 'f1': 0.2092, 'accuracy-SBM': 0.28647, 'auc': 0.61164}
> Epoch 6: took 238.9s (avg 236.7s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 7, 'time_epoch': 205.44665, 'eta': 8428.58397, 'eta_hours': 2.34127, 'loss': 0.84522805, 'lr': 0.00099513, 'params': 183470, 'time_iter': 2.60059, 'accuracy': 0.69004, 'f1': 0.69004, 'accuracy-SBM': 0.69004, 'auc': 0.92793}
val: {'epoch': 7, 'time_epoch': 19.68876, 'loss': 22.94194615, 'lr': 0, 'params': 183470, 'time_iter': 2.46109, 'accuracy': 0.08224, 'f1': 0.07361, 'accuracy-SBM': 0.08277, 'auc': 0.40861}
test: {'epoch': 7, 'time_epoch': 19.88029, 'loss': 23.40581039, 'lr': 0, 'params': 183470, 'time_iter': 2.48504, 'accuracy': 0.08039, 'f1': 0.07258, 'accuracy-SBM': 0.08079, 'auc': 0.40816}
> Epoch 7: took 245.9s (avg 237.9s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 8, 'time_epoch': 215.76143, 'eta': 8296.60509, 'eta_hours': 2.30461, 'loss': 0.82610379, 'lr': 0.00098907, 'params': 183470, 'time_iter': 2.73116, 'accuracy': 0.69756, 'f1': 0.69756, 'accuracy-SBM': 0.69756, 'auc': 0.93121}
val: {'epoch': 8, 'time_epoch': 18.78078, 'loss': 7.04227318, 'lr': 0, 'params': 183470, 'time_iter': 2.3476, 'accuracy': 0.16371, 'f1': 0.10091, 'accuracy-SBM': 0.16184, 'auc': 0.45177}
test: {'epoch': 8, 'time_epoch': 17.57228, 'loss': 7.05310687, 'lr': 0, 'params': 183470, 'time_iter': 2.19654, 'accuracy': 0.16458, 'f1': 0.10346, 'accuracy-SBM': 0.16517, 'auc': 0.45635}
> Epoch 8: took 253.0s (avg 239.6s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 9, 'time_epoch': 198.81191, 'eta': 8080.07161, 'eta_hours': 2.24446, 'loss': 0.81307811, 'lr': 0.00098063, 'params': 183470, 'time_iter': 2.51661, 'accuracy': 0.70216, 'f1': 0.70216, 'accuracy-SBM': 0.70216, 'auc': 0.93338}
val: {'epoch': 9, 'time_epoch': 18.89913, 'loss': 4.27882356, 'lr': 0, 'params': 183470, 'time_iter': 2.36239, 'accuracy': 0.16794, 'f1': 0.13485, 'accuracy-SBM': 0.16938, 'auc': 0.51779}
test: {'epoch': 9, 'time_epoch': 18.45059, 'loss': 4.24233197, 'lr': 0, 'params': 183470, 'time_iter': 2.30632, 'accuracy': 0.17178, 'f1': 0.13745, 'accuracy-SBM': 0.17323, 'auc': 0.52195}
> Epoch 9: took 237.0s (avg 239.3s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 10, 'time_epoch': 202.77682, 'eta': 7880.81766, 'eta_hours': 2.18912, 'loss': 0.80042598, 'lr': 0.00096985, 'params': 183470, 'time_iter': 2.5668, 'accuracy': 0.70733, 'f1': 0.70733, 'accuracy-SBM': 0.70733, 'auc': 0.93546}
val: {'epoch': 10, 'time_epoch': 17.41841, 'loss': 4.67693614, 'lr': 0, 'params': 183470, 'time_iter': 2.1773, 'accuracy': 0.12968, 'f1': 0.09298, 'accuracy-SBM': 0.13011, 'auc': 0.44783}
test: {'epoch': 10, 'time_epoch': 18.54871, 'loss': 4.71746896, 'lr': 0, 'params': 183470, 'time_iter': 2.31859, 'accuracy': 0.13454, 'f1': 0.09769, 'accuracy-SBM': 0.13546, 'auc': 0.45351}
> Epoch 10: took 239.6s (avg 239.3s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 11, 'time_epoch': 219.57699, 'eta': 7734.17708, 'eta_hours': 2.14838, 'loss': 0.79199028, 'lr': 0.00095677, 'params': 183470, 'time_iter': 2.77946, 'accuracy': 0.71038, 'f1': 0.71038, 'accuracy-SBM': 0.71038, 'auc': 0.93683}
val: {'epoch': 11, 'time_epoch': 19.87782, 'loss': 3.89975928, 'lr': 0, 'params': 183470, 'time_iter': 2.48473, 'accuracy': 0.14162, 'f1': 0.09107, 'accuracy-SBM': 0.14385, 'auc': 0.41684}
test: {'epoch': 11, 'time_epoch': 18.38099, 'loss': 3.85222528, 'lr': 0, 'params': 183470, 'time_iter': 2.29762, 'accuracy': 0.14542, 'f1': 0.09587, 'accuracy-SBM': 0.14572, 'auc': 0.41923}
> Epoch 11: took 258.8s (avg 241.0s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 12, 'time_epoch': 198.95703, 'eta': 7517.62794, 'eta_hours': 2.08823, 'loss': 0.7818761, 'lr': 0.00094147, 'params': 183470, 'time_iter': 2.51844, 'accuracy': 0.71408, 'f1': 0.71408, 'accuracy-SBM': 0.71408, 'auc': 0.93845}
val: {'epoch': 12, 'time_epoch': 15.33781, 'loss': 2.30535626, 'lr': 0, 'params': 183470, 'time_iter': 1.91723, 'accuracy': 0.30014, 'f1': 0.24844, 'accuracy-SBM': 0.30286, 'auc': 0.65143}
test: {'epoch': 12, 'time_epoch': 15.68703, 'loss': 2.26088503, 'lr': 0, 'params': 183470, 'time_iter': 1.96088, 'accuracy': 0.31109, 'f1': 0.25616, 'accuracy-SBM': 0.31076, 'auc': 0.65958}
> Epoch 12: took 230.7s (avg 240.2s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 13, 'time_epoch': 178.32973, 'eta': 7250.55035, 'eta_hours': 2.01404, 'loss': 0.77582229, 'lr': 0.00092402, 'params': 183470, 'time_iter': 2.25734, 'accuracy': 0.71627, 'f1': 0.71626, 'accuracy-SBM': 0.71627, 'auc': 0.93941}
val: {'epoch': 13, 'time_epoch': 16.48908, 'loss': 3.21085587, 'lr': 0, 'params': 183470, 'time_iter': 2.06113, 'accuracy': 0.22665, 'f1': 0.21219, 'accuracy-SBM': 0.22664, 'auc': 0.56911}
test: {'epoch': 13, 'time_epoch': 16.5436, 'loss': 3.17172076, 'lr': 0, 'params': 183470, 'time_iter': 2.06795, 'accuracy': 0.23044, 'f1': 0.2178, 'accuracy-SBM': 0.22925, 'auc': 0.57278}
> Epoch 13: took 212.1s (avg 238.2s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 14, 'time_epoch': 192.61663, 'eta': 7028.64189, 'eta_hours': 1.9524, 'loss': 0.76988776, 'lr': 0.00090451, 'params': 183470, 'time_iter': 2.43819, 'accuracy': 0.71837, 'f1': 0.71837, 'accuracy-SBM': 0.71838, 'auc': 0.94034}
val: {'epoch': 14, 'time_epoch': 20.11766, 'loss': 3.62287071, 'lr': 0, 'params': 183470, 'time_iter': 2.51471, 'accuracy': 0.21205, 'f1': 0.127, 'accuracy-SBM': 0.2158, 'auc': 0.54167}
test: {'epoch': 14, 'time_epoch': 20.11125, 'loss': 3.56362779, 'lr': 0, 'params': 183470, 'time_iter': 2.51391, 'accuracy': 0.21727, 'f1': 0.13173, 'accuracy-SBM': 0.21812, 'auc': 0.55044}
> Epoch 14: took 233.8s (avg 237.9s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 15, 'time_epoch': 211.9511, 'eta': 6851.48066, 'eta_hours': 1.90319, 'loss': 0.76513168, 'lr': 0.00088302, 'params': 183470, 'time_iter': 2.68293, 'accuracy': 0.72021, 'f1': 0.72021, 'accuracy-SBM': 0.72021, 'auc': 0.94108}
val: {'epoch': 15, 'time_epoch': 18.85679, 'loss': 2.06959667, 'lr': 0, 'params': 183470, 'time_iter': 2.3571, 'accuracy': 0.28465, 'f1': 0.21217, 'accuracy-SBM': 0.28383, 'auc': 0.65409}
test: {'epoch': 15, 'time_epoch': 18.6217, 'loss': 2.05127934, 'lr': 0, 'params': 183470, 'time_iter': 2.32771, 'accuracy': 0.2869, 'f1': 0.21433, 'accuracy-SBM': 0.28565, 'auc': 0.66094}
> Epoch 15: took 250.3s (avg 238.6s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 16, 'time_epoch': 203.19189, 'eta': 6653.22335, 'eta_hours': 1.84812, 'loss': 0.75828458, 'lr': 0.00085967, 'params': 183470, 'time_iter': 2.57205, 'accuracy': 0.72277, 'f1': 0.72277, 'accuracy-SBM': 0.72277, 'auc': 0.94213}
val: {'epoch': 16, 'time_epoch': 17.13314, 'loss': 2.58905623, 'lr': 0, 'params': 183470, 'time_iter': 2.14164, 'accuracy': 0.20123, 'f1': 0.12697, 'accuracy-SBM': 0.20135, 'auc': 0.46049}
test: {'epoch': 16, 'time_epoch': 18.60232, 'loss': 2.58608938, 'lr': 0, 'params': 183470, 'time_iter': 2.32529, 'accuracy': 0.19845, 'f1': 0.12408, 'accuracy-SBM': 0.19917, 'auc': 0.46229}
> Epoch 16: took 239.8s (avg 238.7s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 17, 'time_epoch': 195.16906, 'eta': 6440.15493, 'eta_hours': 1.78893, 'loss': 0.75256357, 'lr': 0.00083457, 'params': 183470, 'time_iter': 2.47049, 'accuracy': 0.72521, 'f1': 0.72521, 'accuracy-SBM': 0.72521, 'auc': 0.943}
val: {'epoch': 17, 'time_epoch': 18.61655, 'loss': 3.33902378, 'lr': 0, 'params': 183470, 'time_iter': 2.32707, 'accuracy': 0.19299, 'f1': 0.17179, 'accuracy-SBM': 0.19356, 'auc': 0.55026}
test: {'epoch': 17, 'time_epoch': 19.18931, 'loss': 3.29301509, 'lr': 0, 'params': 183470, 'time_iter': 2.39866, 'accuracy': 0.19859, 'f1': 0.17656, 'accuracy-SBM': 0.19786, 'auc': 0.55489}
> Epoch 17: took 233.8s (avg 238.4s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 18, 'time_epoch': 209.09421, 'eta': 6251.69064, 'eta_hours': 1.73658, 'loss': 0.75040303, 'lr': 0.00080783, 'params': 183470, 'time_iter': 2.64676, 'accuracy': 0.72571, 'f1': 0.72571, 'accuracy-SBM': 0.72571, 'auc': 0.94334}
val: {'epoch': 18, 'time_epoch': 18.73096, 'loss': 2.32356408, 'lr': 0, 'params': 183470, 'time_iter': 2.34137, 'accuracy': 0.22314, 'f1': 0.14206, 'accuracy-SBM': 0.22157, 'auc': 0.6007}
test: {'epoch': 18, 'time_epoch': 15.41617, 'loss': 2.30765682, 'lr': 0, 'params': 183470, 'time_iter': 1.92702, 'accuracy': 0.22528, 'f1': 0.14435, 'accuracy-SBM': 0.22293, 'auc': 0.60322}
> Epoch 18: took 244.1s (avg 238.7s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 19, 'time_epoch': 202.76748, 'eta': 6051.67326, 'eta_hours': 1.68102, 'loss': 0.74537777, 'lr': 0.0007796, 'params': 183470, 'time_iter': 2.56668, 'accuracy': 0.72746, 'f1': 0.72745, 'accuracy-SBM': 0.72746, 'auc': 0.9441}
val: {'epoch': 19, 'time_epoch': 18.71894, 'loss': 2.40125279, 'lr': 0, 'params': 183470, 'time_iter': 2.33987, 'accuracy': 0.29535, 'f1': 0.22423, 'accuracy-SBM': 0.29828, 'auc': 0.59892}
test: {'epoch': 19, 'time_epoch': 18.32796, 'loss': 2.37770243, 'lr': 0, 'params': 183470, 'time_iter': 2.29099, 'accuracy': 0.30513, 'f1': 0.23353, 'accuracy-SBM': 0.30619, 'auc': 0.60647}
> Epoch 19: took 240.6s (avg 238.8s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 20, 'time_epoch': 203.6196, 'eta': 5852.5707, 'eta_hours': 1.62571, 'loss': 0.73931023, 'lr': 0.00075, 'params': 183470, 'time_iter': 2.57746, 'accuracy': 0.72976, 'f1': 0.72976, 'accuracy-SBM': 0.72976, 'auc': 0.94502}
val: {'epoch': 20, 'time_epoch': 18.8256, 'loss': 2.65302918, 'lr': 0, 'params': 183470, 'time_iter': 2.3532, 'accuracy': 0.23625, 'f1': 0.17172, 'accuracy-SBM': 0.23941, 'auc': 0.61632}
test: {'epoch': 20, 'time_epoch': 15.60134, 'loss': 2.59633544, 'lr': 0, 'params': 183470, 'time_iter': 1.95017, 'accuracy': 0.24211, 'f1': 0.1762, 'accuracy-SBM': 0.24208, 'auc': 0.62461}
> Epoch 20: took 238.8s (avg 238.8s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 21, 'time_epoch': 213.65137, 'eta': 5665.82521, 'eta_hours': 1.57384, 'loss': 0.73752571, 'lr': 0.00071919, 'params': 183470, 'time_iter': 2.70445, 'accuracy': 0.73052, 'f1': 0.73052, 'accuracy-SBM': 0.73052, 'auc': 0.94528}
val: {'epoch': 21, 'time_epoch': 19.61175, 'loss': 2.05616349, 'lr': 0, 'params': 183470, 'time_iter': 2.45147, 'accuracy': 0.31223, 'f1': 0.24618, 'accuracy-SBM': 0.31355, 'auc': 0.6888}
test: {'epoch': 21, 'time_epoch': 20.2792, 'loss': 2.02156006, 'lr': 0, 'params': 183470, 'time_iter': 2.5349, 'accuracy': 0.31993, 'f1': 0.25447, 'accuracy-SBM': 0.32046, 'auc': 0.69844}
> Epoch 21: took 254.4s (avg 239.5s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 22, 'time_epoch': 207.56209, 'eta': 5469.59179, 'eta_hours': 1.51933, 'loss': 0.73514898, 'lr': 0.0006873, 'params': 183470, 'time_iter': 2.62737, 'accuracy': 0.73146, 'f1': 0.73146, 'accuracy-SBM': 0.73146, 'auc': 0.94562}
val: {'epoch': 22, 'time_epoch': 18.65392, 'loss': 2.97274055, 'lr': 0, 'params': 183470, 'time_iter': 2.33174, 'accuracy': 0.12681, 'f1': 0.12108, 'accuracy-SBM': 0.12609, 'auc': 0.49037}
test: {'epoch': 22, 'time_epoch': 13.77337, 'loss': 2.99276432, 'lr': 0, 'params': 183470, 'time_iter': 1.72167, 'accuracy': 0.12992, 'f1': 0.12314, 'accuracy-SBM': 0.12965, 'auc': 0.49206}
> Epoch 22: took 240.8s (avg 239.6s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 23, 'time_epoch': 197.07929, 'eta': 5261.05795, 'eta_hours': 1.4614, 'loss': 0.73079598, 'lr': 0.00065451, 'params': 183470, 'time_iter': 2.49467, 'accuracy': 0.73318, 'f1': 0.73318, 'accuracy-SBM': 0.73318, 'auc': 0.94628}
val: {'epoch': 23, 'time_epoch': 18.81831, 'loss': 2.61423189, 'lr': 0, 'params': 183470, 'time_iter': 2.35229, 'accuracy': 0.16912, 'f1': 0.15793, 'accuracy-SBM': 0.1705, 'auc': 0.48791}
test: {'epoch': 23, 'time_epoch': 16.95522, 'loss': 2.59099521, 'lr': 0, 'params': 183470, 'time_iter': 2.1194, 'accuracy': 0.17247, 'f1': 0.1621, 'accuracy-SBM': 0.17267, 'auc': 0.49019}
> Epoch 23: took 233.6s (avg 239.3s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 24, 'time_epoch': 202.88741, 'eta': 5059.2486, 'eta_hours': 1.40535, 'loss': 0.72844772, 'lr': 0.00062096, 'params': 183470, 'time_iter': 2.5682, 'accuracy': 0.73381, 'f1': 0.73381, 'accuracy-SBM': 0.73381, 'auc': 0.94663}
val: {'epoch': 24, 'time_epoch': 16.45243, 'loss': 2.09504641, 'lr': 0, 'params': 183470, 'time_iter': 2.05655, 'accuracy': 0.35026, 'f1': 0.30526, 'accuracy-SBM': 0.35271, 'auc': 0.70411}
test: {'epoch': 24, 'time_epoch': 20.00572, 'loss': 2.07532531, 'lr': 0, 'params': 183470, 'time_iter': 2.50072, 'accuracy': 0.35973, 'f1': 0.31654, 'accuracy-SBM': 0.36082, 'auc': 0.7081}
> Epoch 24: took 240.2s (avg 239.4s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 25, 'time_epoch': 198.10013, 'eta': 4852.93729, 'eta_hours': 1.34804, 'loss': 0.72366886, 'lr': 0.00058682, 'params': 183470, 'time_iter': 2.5076, 'accuracy': 0.73581, 'f1': 0.73581, 'accuracy-SBM': 0.73581, 'auc': 0.94732}
val: {'epoch': 25, 'time_epoch': 16.78728, 'loss': 2.44364671, 'lr': 0, 'params': 183470, 'time_iter': 2.09841, 'accuracy': 0.27566, 'f1': 0.24139, 'accuracy-SBM': 0.27777, 'auc': 0.61309}
test: {'epoch': 25, 'time_epoch': 18.19056, 'loss': 2.43764544, 'lr': 0, 'params': 183470, 'time_iter': 2.27382, 'accuracy': 0.27815, 'f1': 0.24503, 'accuracy-SBM': 0.27917, 'auc': 0.61536}
> Epoch 25: took 233.9s (avg 239.2s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 26, 'time_epoch': 201.75883, 'eta': 4650.35089, 'eta_hours': 1.29176, 'loss': 0.7214943, 'lr': 0.00055226, 'params': 183470, 'time_iter': 2.55391, 'accuracy': 0.7364, 'f1': 0.7364, 'accuracy-SBM': 0.7364, 'auc': 0.94764}
val: {'epoch': 26, 'time_epoch': 18.29876, 'loss': 2.77869064, 'lr': 0, 'params': 183470, 'time_iter': 2.28735, 'accuracy': 0.25952, 'f1': 0.18671, 'accuracy-SBM': 0.26281, 'auc': 0.64646}
test: {'epoch': 26, 'time_epoch': 17.95384, 'loss': 2.75871888, 'lr': 0, 'params': 183470, 'time_iter': 2.24423, 'accuracy': 0.26874, 'f1': 0.1939, 'accuracy-SBM': 0.26992, 'auc': 0.6516}
> Epoch 26: took 238.9s (avg 239.2s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 27, 'time_epoch': 194.1297, 'eta': 4441.82928, 'eta_hours': 1.23384, 'loss': 0.71766025, 'lr': 0.00051745, 'params': 183470, 'time_iter': 2.45734, 'accuracy': 0.73774, 'f1': 0.73773, 'accuracy-SBM': 0.73774, 'auc': 0.94821}
val: {'epoch': 27, 'time_epoch': 17.20093, 'loss': 2.58176083, 'lr': 0, 'params': 183470, 'time_iter': 2.15012, 'accuracy': 0.28228, 'f1': 0.23827, 'accuracy-SBM': 0.28138, 'auc': 0.60529}
test: {'epoch': 27, 'time_epoch': 17.40307, 'loss': 2.59573114, 'lr': 0, 'params': 183470, 'time_iter': 2.17538, 'accuracy': 0.27481, 'f1': 0.23463, 'accuracy-SBM': 0.27413, 'auc': 0.60284}
> Epoch 27: took 229.6s (avg 238.8s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 28, 'time_epoch': 204.62722, 'eta': 4241.90186, 'eta_hours': 1.17831, 'loss': 0.71433143, 'lr': 0.00048255, 'params': 183470, 'time_iter': 2.59022, 'accuracy': 0.73906, 'f1': 0.73905, 'accuracy-SBM': 0.73906, 'auc': 0.94868}
val: {'epoch': 28, 'time_epoch': 20.30536, 'loss': 4.80882345, 'lr': 0, 'params': 183470, 'time_iter': 2.53817, 'accuracy': 0.2289, 'f1': 0.15714, 'accuracy-SBM': 0.23269, 'auc': 0.56632}
test: {'epoch': 28, 'time_epoch': 12.54488, 'loss': 4.61470098, 'lr': 0, 'params': 183470, 'time_iter': 1.56811, 'accuracy': 0.23754, 'f1': 0.1654, 'accuracy-SBM': 0.23848, 'auc': 0.57274}
> Epoch 28: took 238.2s (avg 238.8s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 29, 'time_epoch': 204.49824, 'eta': 4041.57515, 'eta_hours': 1.12266, 'loss': 0.7129415, 'lr': 0.00044774, 'params': 183470, 'time_iter': 2.58859, 'accuracy': 0.7393, 'f1': 0.7393, 'accuracy-SBM': 0.7393, 'auc': 0.94888}
val: {'epoch': 29, 'time_epoch': 18.87915, 'loss': 3.07131307, 'lr': 0, 'params': 183470, 'time_iter': 2.35989, 'accuracy': 0.25707, 'f1': 0.20444, 'accuracy-SBM': 0.25658, 'auc': 0.5765}
test: {'epoch': 29, 'time_epoch': 14.88763, 'loss': 3.05451694, 'lr': 0, 'params': 183470, 'time_iter': 1.86095, 'accuracy': 0.26448, 'f1': 0.2109, 'accuracy-SBM': 0.26246, 'auc': 0.57992}
> Epoch 29: took 239.2s (avg 238.8s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 30, 'time_epoch': 195.81583, 'eta': 3835.65782, 'eta_hours': 1.06546, 'loss': 0.71120047, 'lr': 0.00041318, 'params': 183470, 'time_iter': 2.47868, 'accuracy': 0.7405, 'f1': 0.7405, 'accuracy-SBM': 0.7405, 'auc': 0.94914}
val: {'epoch': 30, 'time_epoch': 18.84468, 'loss': 2.11492626, 'lr': 0, 'params': 183470, 'time_iter': 2.35558, 'accuracy': 0.33381, 'f1': 0.26999, 'accuracy-SBM': 0.33757, 'auc': 0.69989}
test: {'epoch': 30, 'time_epoch': 18.55913, 'loss': 2.09381874, 'lr': 0, 'params': 183470, 'time_iter': 2.31989, 'accuracy': 0.33964, 'f1': 0.27553, 'accuracy-SBM': 0.34134, 'auc': 0.70346}
> Epoch 30: took 234.0s (avg 238.7s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 31, 'time_epoch': 185.18343, 'eta': 3624.39111, 'eta_hours': 1.00678, 'loss': 0.7074547, 'lr': 0.00037904, 'params': 183470, 'time_iter': 2.34409, 'accuracy': 0.74133, 'f1': 0.74133, 'accuracy-SBM': 0.74133, 'auc': 0.94967}
val: {'epoch': 31, 'time_epoch': 17.80206, 'loss': 2.59026734, 'lr': 0, 'params': 183470, 'time_iter': 2.22526, 'accuracy': 0.32593, 'f1': 0.24597, 'accuracy-SBM': 0.32948, 'auc': 0.66032}
test: {'epoch': 31, 'time_epoch': 17.77047, 'loss': 2.51889651, 'lr': 0, 'params': 183470, 'time_iter': 2.22131, 'accuracy': 0.33795, 'f1': 0.25953, 'accuracy-SBM': 0.34024, 'auc': 0.6711}
> Epoch 31: took 221.6s (avg 238.1s) | Best so far: epoch 3	train loss: 1.0087 train_accuracy-SBM: 0.6276	val loss: 2.5876 val_accuracy-SBM: 0.4283	test loss: 2.5788 test_accuracy-SBM: 0.4340
train: {'epoch': 32, 'time_epoch': 185.35755, 'eta': 3414.79491, 'eta_hours': 0.94855, 'loss': 0.70604815, 'lr': 0.00034549, 'params': 183470, 'time_iter': 2.3463, 'accuracy': 0.74196, 'f1': 0.74196, 'accuracy-SBM': 0.74196, 'auc': 0.94987}
val: {'epoch': 32, 'time_epoch': 16.32703, 'loss': 1.52720827, 'lr': 0, 'params': 183470, 'time_iter': 2.04088, 'accuracy': 0.44702, 'f1': 0.41244, 'accuracy-SBM': 0.4468, 'auc': 0.76993}
test: {'epoch': 32, 'time_epoch': 16.34409, 'loss': 1.50800226, 'lr': 0, 'params': 183470, 'time_iter': 2.04301, 'accuracy': 0.45384, 'f1': 0.42075, 'accuracy-SBM': 0.45516, 'auc': 0.77525}
> Epoch 32: took 218.8s (avg 237.5s) | Best so far: epoch 32	train loss: 0.7060 train_accuracy-SBM: 0.7420	val loss: 1.5272 val_accuracy-SBM: 0.4468	test loss: 1.5080 test_accuracy-SBM: 0.4552
train: {'epoch': 33, 'time_epoch': 197.94352, 'eta': 3212.54732, 'eta_hours': 0.89237, 'loss': 0.70365589, 'lr': 0.0003127, 'params': 183470, 'time_iter': 2.50561, 'accuracy': 0.74296, 'f1': 0.74296, 'accuracy-SBM': 0.74296, 'auc': 0.95021}
val: {'epoch': 33, 'time_epoch': 18.66047, 'loss': 1.33311922, 'lr': 0, 'params': 183470, 'time_iter': 2.33256, 'accuracy': 0.54388, 'f1': 0.53781, 'accuracy-SBM': 0.54312, 'auc': 0.84285}
test: {'epoch': 33, 'time_epoch': 18.11927, 'loss': 1.30146999, 'lr': 0, 'params': 183470, 'time_iter': 2.26491, 'accuracy': 0.54402, 'f1': 0.5374, 'accuracy-SBM': 0.54417, 'auc': 0.84823}
> Epoch 33: took 235.5s (avg 237.5s) | Best so far: epoch 33	train loss: 0.7037 train_accuracy-SBM: 0.7430	val loss: 1.3331 val_accuracy-SBM: 0.5431	test loss: 1.3015 test_accuracy-SBM: 0.5442
train: {'epoch': 34, 'time_epoch': 202.42556, 'eta': 3012.46655, 'eta_hours': 0.8368, 'loss': 0.70218175, 'lr': 0.00028081, 'params': 183470, 'time_iter': 2.56235, 'accuracy': 0.74333, 'f1': 0.74332, 'accuracy-SBM': 0.74332, 'auc': 0.95043}
val: {'epoch': 34, 'time_epoch': 18.89529, 'loss': 1.89788498, 'lr': 0, 'params': 183470, 'time_iter': 2.36191, 'accuracy': 0.422, 'f1': 0.3675, 'accuracy-SBM': 0.42446, 'auc': 0.7504}
test: {'epoch': 34, 'time_epoch': 18.52342, 'loss': 1.88665968, 'lr': 0, 'params': 183470, 'time_iter': 2.31543, 'accuracy': 0.42524, 'f1': 0.37062, 'accuracy-SBM': 0.42712, 'auc': 0.75033}
> Epoch 34: took 240.6s (avg 237.6s) | Best so far: epoch 33	train loss: 0.7037 train_accuracy-SBM: 0.7430	val loss: 1.3331 val_accuracy-SBM: 0.5431	test loss: 1.3015 test_accuracy-SBM: 0.5442
train: {'epoch': 35, 'time_epoch': 216.70367, 'eta': 2817.80811, 'eta_hours': 0.78272, 'loss': 0.6996706, 'lr': 0.00025, 'params': 183470, 'time_iter': 2.74308, 'accuracy': 0.74445, 'f1': 0.74445, 'accuracy-SBM': 0.74445, 'auc': 0.95077}
val: {'epoch': 35, 'time_epoch': 20.5533, 'loss': 2.16697462, 'lr': 0, 'params': 183470, 'time_iter': 2.56916, 'accuracy': 0.45806, 'f1': 0.38772, 'accuracy-SBM': 0.45755, 'auc': 0.76625}
test: {'epoch': 35, 'time_epoch': 19.06471, 'loss': 2.13579526, 'lr': 0, 'params': 183470, 'time_iter': 2.38309, 'accuracy': 0.46302, 'f1': 0.39404, 'accuracy-SBM': 0.46268, 'auc': 0.76908}
> Epoch 35: took 257.3s (avg 238.1s) | Best so far: epoch 33	train loss: 0.7037 train_accuracy-SBM: 0.7430	val loss: 1.3331 val_accuracy-SBM: 0.5431	test loss: 1.3015 test_accuracy-SBM: 0.5442
train: {'epoch': 36, 'time_epoch': 201.45451, 'eta': 2616.60023, 'eta_hours': 0.72683, 'loss': 0.69894173, 'lr': 0.0002204, 'params': 183470, 'time_iter': 2.55006, 'accuracy': 0.74452, 'f1': 0.74452, 'accuracy-SBM': 0.74452, 'auc': 0.95087}
val: {'epoch': 36, 'time_epoch': 18.75403, 'loss': 1.45120028, 'lr': 0, 'params': 183470, 'time_iter': 2.34425, 'accuracy': 0.48773, 'f1': 0.45391, 'accuracy-SBM': 0.48784, 'auc': 0.80433}
test: {'epoch': 36, 'time_epoch': 17.9983, 'loss': 1.41827393, 'lr': 0, 'params': 183470, 'time_iter': 2.24979, 'accuracy': 0.49758, 'f1': 0.46363, 'accuracy-SBM': 0.49748, 'auc': 0.81246}
> Epoch 36: took 239.0s (avg 238.1s) | Best so far: epoch 33	train loss: 0.7037 train_accuracy-SBM: 0.7430	val loss: 1.3331 val_accuracy-SBM: 0.5431	test loss: 1.3015 test_accuracy-SBM: 0.5442
train: {'epoch': 37, 'time_epoch': 195.47857, 'eta': 2413.49222, 'eta_hours': 0.67041, 'loss': 0.69784972, 'lr': 0.00019217, 'params': 183470, 'time_iter': 2.47441, 'accuracy': 0.74535, 'f1': 0.74535, 'accuracy-SBM': 0.74535, 'auc': 0.95104}
val: {'epoch': 37, 'time_epoch': 17.87957, 'loss': 1.56190269, 'lr': 0, 'params': 183470, 'time_iter': 2.23495, 'accuracy': 0.49136, 'f1': 0.44519, 'accuracy-SBM': 0.48934, 'auc': 0.80392}
test: {'epoch': 37, 'time_epoch': 17.73081, 'loss': 1.55430007, 'lr': 0, 'params': 183470, 'time_iter': 2.21635, 'accuracy': 0.49409, 'f1': 0.45166, 'accuracy-SBM': 0.4948, 'auc': 0.80725}
> Epoch 37: took 232.2s (avg 238.0s) | Best so far: epoch 33	train loss: 0.7037 train_accuracy-SBM: 0.7430	val loss: 1.3331 val_accuracy-SBM: 0.5431	test loss: 1.3015 test_accuracy-SBM: 0.5442
train: {'epoch': 38, 'time_epoch': 209.36126, 'eta': 2214.6911, 'eta_hours': 0.61519, 'loss': 0.6958071, 'lr': 0.00016543, 'params': 183470, 'time_iter': 2.65014, 'accuracy': 0.74571, 'f1': 0.74571, 'accuracy-SBM': 0.74571, 'auc': 0.95132}
val: {'epoch': 38, 'time_epoch': 20.17387, 'loss': 1.41654764, 'lr': 0, 'params': 183470, 'time_iter': 2.52173, 'accuracy': 0.51859, 'f1': 0.49263, 'accuracy-SBM': 0.52039, 'auc': 0.83203}
test: {'epoch': 38, 'time_epoch': 19.81468, 'loss': 1.39471864, 'lr': 0, 'params': 183470, 'time_iter': 2.47683, 'accuracy': 0.52747, 'f1': 0.50226, 'accuracy-SBM': 0.52795, 'auc': 0.83693}
> Epoch 38: took 250.3s (avg 238.3s) | Best so far: epoch 33	train loss: 0.7037 train_accuracy-SBM: 0.7430	val loss: 1.3331 val_accuracy-SBM: 0.5431	test loss: 1.3015 test_accuracy-SBM: 0.5442
train: {'epoch': 39, 'time_epoch': 212.48092, 'eta': 2016.14189, 'eta_hours': 0.56004, 'loss': 0.69438095, 'lr': 0.00014033, 'params': 183470, 'time_iter': 2.68963, 'accuracy': 0.74636, 'f1': 0.74636, 'accuracy-SBM': 0.74636, 'auc': 0.95153}
val: {'epoch': 39, 'time_epoch': 18.92567, 'loss': 0.99859952, 'lr': 0, 'params': 183470, 'time_iter': 2.36571, 'accuracy': 0.63142, 'f1': 0.61955, 'accuracy-SBM': 0.63001, 'auc': 0.90692}
test: {'epoch': 39, 'time_epoch': 18.63666, 'loss': 0.99558571, 'lr': 0, 'params': 183470, 'time_iter': 2.32958, 'accuracy': 0.63251, 'f1': 0.62134, 'accuracy-SBM': 0.63258, 'auc': 0.90762}
> Epoch 39: took 250.9s (avg 238.6s) | Best so far: epoch 39	train loss: 0.6944 train_accuracy-SBM: 0.7464	val loss: 0.9986 val_accuracy-SBM: 0.6300	test loss: 0.9956 test_accuracy-SBM: 0.6326
train: {'epoch': 40, 'time_epoch': 202.01769, 'eta': 1814.61627, 'eta_hours': 0.50406, 'loss': 0.6927001, 'lr': 0.00011698, 'params': 183470, 'time_iter': 2.55719, 'accuracy': 0.74653, 'f1': 0.74653, 'accuracy-SBM': 0.74653, 'auc': 0.95176}
val: {'epoch': 40, 'time_epoch': 18.42468, 'loss': 1.05430023, 'lr': 0, 'params': 183470, 'time_iter': 2.30309, 'accuracy': 0.61371, 'f1': 0.60717, 'accuracy-SBM': 0.61352, 'auc': 0.89592}
test: {'epoch': 40, 'time_epoch': 18.1293, 'loss': 1.0351031, 'lr': 0, 'params': 183470, 'time_iter': 2.26616, 'accuracy': 0.62072, 'f1': 0.61496, 'accuracy-SBM': 0.62088, 'auc': 0.9007}
> Epoch 40: took 239.4s (avg 238.6s) | Best so far: epoch 39	train loss: 0.6944 train_accuracy-SBM: 0.7464	val loss: 0.9986 val_accuracy-SBM: 0.6300	test loss: 0.9956 test_accuracy-SBM: 0.6326
train: {'epoch': 41, 'time_epoch': 203.33642, 'eta': 1613.31841, 'eta_hours': 0.44814, 'loss': 0.69171987, 'lr': 9.549e-05, 'params': 183470, 'time_iter': 2.57388, 'accuracy': 0.7473, 'f1': 0.7473, 'accuracy-SBM': 0.7473, 'auc': 0.95189}
val: {'epoch': 41, 'time_epoch': 18.8579, 'loss': 0.94163856, 'lr': 0, 'params': 183470, 'time_iter': 2.35724, 'accuracy': 0.66699, 'f1': 0.66514, 'accuracy-SBM': 0.6677, 'auc': 0.91892}
test: {'epoch': 41, 'time_epoch': 18.41707, 'loss': 0.92414589, 'lr': 0, 'params': 183470, 'time_iter': 2.30213, 'accuracy': 0.67512, 'f1': 0.67237, 'accuracy-SBM': 0.67507, 'auc': 0.9214}
> Epoch 41: took 241.4s (avg 238.7s) | Best so far: epoch 41	train loss: 0.6917 train_accuracy-SBM: 0.7473	val loss: 0.9416 val_accuracy-SBM: 0.6677	test loss: 0.9241 test_accuracy-SBM: 0.6751
train: {'epoch': 42, 'time_epoch': 220.17877, 'eta': 1414.66751, 'eta_hours': 0.39296, 'loss': 0.69134324, 'lr': 7.598e-05, 'params': 183470, 'time_iter': 2.78707, 'accuracy': 0.74744, 'f1': 0.74744, 'accuracy-SBM': 0.74744, 'auc': 0.95195}
val: {'epoch': 42, 'time_epoch': 18.66191, 'loss': 0.98504714, 'lr': 0, 'params': 183470, 'time_iter': 2.33274, 'accuracy': 0.65102, 'f1': 0.64646, 'accuracy-SBM': 0.65154, 'auc': 0.91105}
test: {'epoch': 42, 'time_epoch': 18.35053, 'loss': 0.97561545, 'lr': 0, 'params': 183470, 'time_iter': 2.29382, 'accuracy': 0.65821, 'f1': 0.6535, 'accuracy-SBM': 0.65775, 'auc': 0.91267}
> Epoch 42: took 258.2s (avg 239.1s) | Best so far: epoch 41	train loss: 0.6917 train_accuracy-SBM: 0.7473	val loss: 0.9416 val_accuracy-SBM: 0.6677	test loss: 0.9241 test_accuracy-SBM: 0.6751
train: {'epoch': 43, 'time_epoch': 203.79493, 'eta': 1212.80391, 'eta_hours': 0.33689, 'loss': 0.69110435, 'lr': 5.853e-05, 'params': 183470, 'time_iter': 2.57968, 'accuracy': 0.74736, 'f1': 0.74736, 'accuracy-SBM': 0.74736, 'auc': 0.95199}
val: {'epoch': 43, 'time_epoch': 17.92562, 'loss': 0.85792188, 'lr': 0, 'params': 183470, 'time_iter': 2.2407, 'accuracy': 0.68766, 'f1': 0.68556, 'accuracy-SBM': 0.68868, 'auc': 0.92843}
test: {'epoch': 43, 'time_epoch': 18.64758, 'loss': 0.85013088, 'lr': 0, 'params': 183470, 'time_iter': 2.33095, 'accuracy': 0.69351, 'f1': 0.69099, 'accuracy-SBM': 0.69375, 'auc': 0.92969}
> Epoch 43: took 241.2s (avg 239.2s) | Best so far: epoch 43	train loss: 0.6911 train_accuracy-SBM: 0.7474	val loss: 0.8579 val_accuracy-SBM: 0.6887	test loss: 0.8501 test_accuracy-SBM: 0.6937
train: {'epoch': 44, 'time_epoch': 201.56879, 'eta': 1010.60713, 'eta_hours': 0.28072, 'loss': 0.68951906, 'lr': 4.323e-05, 'params': 183470, 'time_iter': 2.5515, 'accuracy': 0.74793, 'f1': 0.74793, 'accuracy-SBM': 0.74793, 'auc': 0.95221}
val: {'epoch': 44, 'time_epoch': 17.21646, 'loss': 0.80041257, 'lr': 0, 'params': 183470, 'time_iter': 2.15206, 'accuracy': 0.70776, 'f1': 0.70652, 'accuracy-SBM': 0.70768, 'auc': 0.93651}
test: {'epoch': 44, 'time_epoch': 18.65378, 'loss': 0.78530306, 'lr': 0, 'params': 183470, 'time_iter': 2.33172, 'accuracy': 0.71323, 'f1': 0.71207, 'accuracy-SBM': 0.71329, 'auc': 0.93875}
> Epoch 44: took 238.2s (avg 239.2s) | Best so far: epoch 44	train loss: 0.6895 train_accuracy-SBM: 0.7479	val loss: 0.8004 val_accuracy-SBM: 0.7077	test loss: 0.7853 test_accuracy-SBM: 0.7133
train: {'epoch': 45, 'time_epoch': 209.93132, 'eta': 809.16482, 'eta_hours': 0.22477, 'loss': 0.68920679, 'lr': 3.015e-05, 'params': 183470, 'time_iter': 2.65736, 'accuracy': 0.748, 'f1': 0.748, 'accuracy-SBM': 0.748, 'auc': 0.95225}
val: {'epoch': 45, 'time_epoch': 20.36849, 'loss': 0.75977223, 'lr': 0, 'params': 183470, 'time_iter': 2.54606, 'accuracy': 0.72625, 'f1': 0.72613, 'accuracy-SBM': 0.72617, 'auc': 0.94294}
test: {'epoch': 45, 'time_epoch': 19.23218, 'loss': 0.75636035, 'lr': 0, 'params': 183470, 'time_iter': 2.40402, 'accuracy': 0.7282, 'f1': 0.72823, 'accuracy-SBM': 0.72817, 'auc': 0.94351}
> Epoch 45: took 250.6s (avg 239.4s) | Best so far: epoch 45	train loss: 0.6892 train_accuracy-SBM: 0.7480	val loss: 0.7598 val_accuracy-SBM: 0.7262	test loss: 0.7564 test_accuracy-SBM: 0.7282
train: {'epoch': 46, 'time_epoch': 207.50225, 'eta': 607.20624, 'eta_hours': 0.16867, 'loss': 0.68937888, 'lr': 1.937e-05, 'params': 183470, 'time_iter': 2.62661, 'accuracy': 0.74813, 'f1': 0.74813, 'accuracy-SBM': 0.74813, 'auc': 0.95222}
val: {'epoch': 46, 'time_epoch': 17.0999, 'loss': 0.76030119, 'lr': 0, 'params': 183470, 'time_iter': 2.13749, 'accuracy': 0.72421, 'f1': 0.72409, 'accuracy-SBM': 0.7242, 'auc': 0.94226}
test: {'epoch': 46, 'time_epoch': 18.543, 'loss': 0.75417521, 'lr': 0, 'params': 183470, 'time_iter': 2.31788, 'accuracy': 0.72574, 'f1': 0.72556, 'accuracy-SBM': 0.72593, 'auc': 0.94326}
> Epoch 46: took 243.9s (avg 239.5s) | Best so far: epoch 45	train loss: 0.6892 train_accuracy-SBM: 0.7480	val loss: 0.7598 val_accuracy-SBM: 0.7262	test loss: 0.7564 test_accuracy-SBM: 0.7282
train: {'epoch': 47, 'time_epoch': 202.90732, 'eta': 404.82521, 'eta_hours': 0.11245, 'loss': 0.68898518, 'lr': 1.093e-05, 'params': 183470, 'time_iter': 2.56845, 'accuracy': 0.74824, 'f1': 0.74824, 'accuracy-SBM': 0.74824, 'auc': 0.95228}
val: {'epoch': 47, 'time_epoch': 18.86524, 'loss': 0.74645769, 'lr': 0, 'params': 183470, 'time_iter': 2.35815, 'accuracy': 0.72946, 'f1': 0.72944, 'accuracy-SBM': 0.72949, 'auc': 0.94442}
test: {'epoch': 47, 'time_epoch': 18.37401, 'loss': 0.74417507, 'lr': 0, 'params': 183470, 'time_iter': 2.29675, 'accuracy': 0.73179, 'f1': 0.73181, 'accuracy-SBM': 0.73182, 'auc': 0.94481}
> Epoch 47: took 241.0s (avg 239.5s) | Best so far: epoch 47	train loss: 0.6890 train_accuracy-SBM: 0.7482	val loss: 0.7465 val_accuracy-SBM: 0.7295	test loss: 0.7442 test_accuracy-SBM: 0.7318
train: {'epoch': 48, 'time_epoch': 203.02362, 'eta': 202.42507, 'eta_hours': 0.05623, 'loss': 0.68833802, 'lr': 4.87e-06, 'params': 183470, 'time_iter': 2.56992, 'accuracy': 0.7486, 'f1': 0.7486, 'accuracy-SBM': 0.7486, 'auc': 0.95236}
val: {'epoch': 48, 'time_epoch': 17.85324, 'loss': 0.73959382, 'lr': 0, 'params': 183470, 'time_iter': 2.23166, 'accuracy': 0.73213, 'f1': 0.73201, 'accuracy-SBM': 0.73202, 'auc': 0.94515}
test: {'epoch': 48, 'time_epoch': 20.17196, 'loss': 0.73565529, 'lr': 0, 'params': 183470, 'time_iter': 2.52149, 'accuracy': 0.73358, 'f1': 0.73356, 'accuracy-SBM': 0.73355, 'auc': 0.94573}
> Epoch 48: took 241.9s (avg 239.6s) | Best so far: epoch 48	train loss: 0.6883 train_accuracy-SBM: 0.7486	val loss: 0.7396 val_accuracy-SBM: 0.7320	test loss: 0.7357 test_accuracy-SBM: 0.7336
train: {'epoch': 49, 'time_epoch': 212.7891, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.68818101, 'lr': 1.22e-06, 'params': 183470, 'time_iter': 2.69353, 'accuracy': 0.74862, 'f1': 0.74862, 'accuracy-SBM': 0.74862, 'auc': 0.95238}
val: {'epoch': 49, 'time_epoch': 16.72083, 'loss': 0.73966971, 'lr': 0, 'params': 183470, 'time_iter': 2.0901, 'accuracy': 0.73225, 'f1': 0.73214, 'accuracy-SBM': 0.73215, 'auc': 0.94515}
test: {'epoch': 49, 'time_epoch': 15.69511, 'loss': 0.73476259, 'lr': 0, 'params': 183470, 'time_iter': 1.96189, 'accuracy': 0.73304, 'f1': 0.73302, 'accuracy-SBM': 0.73303, 'auc': 0.94588}
> Epoch 49: took 246.0s (avg 239.7s) | Best so far: epoch 49	train loss: 0.6882 train_accuracy-SBM: 0.7486	val loss: 0.7397 val_accuracy-SBM: 0.7321	test loss: 0.7348 test_accuracy-SBM: 0.7330
Avg time per epoch: 239.72s
Total train loop time: 3.33h
Task done, results saved in tests/results/cluster/gat-s2gnn-100k/2025-05-12/22-08-25-327497-cluster-gat-s2gnn-100k/11
Failed when trying to aggregate multiple runs: Tensorboard support requires `tensorboardX`.
[*] All done: 2025-05-13 01:30:10.473704
