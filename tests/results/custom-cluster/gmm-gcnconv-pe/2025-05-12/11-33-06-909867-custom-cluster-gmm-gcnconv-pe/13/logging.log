[*] Run ID 13: seed=13, split_index=0
    Starting now: 2025-05-12 11:33:07.131741
[*] Loaded dataset 'custom-cluster-gmm' from 'synthetic':
  Data(x=[10762802, 7], edge_index=[2, 74341144], y=[10762802])
  undirected: True
  num graphs: 12000
  avg num_nodes/graph: 896
  num node features: 7
  num edge features: 0
  num classes: 6
Precomputing Positional Encoding statistics: ['MagLapPE'] for all graphs...
  ...estimated to be undirected: True
Done! Took 00:01:49.63
GraphGymModule(
  (model): S2GNN(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): LinearNodeEncoder(
          (encoder): Linear(in_features=7, out_features=128, bias=True)
        )
        (encoder2): MagLapPENodeEncoder(
          (posenc_lin): Linear(in_features=10, out_features=128, bias=True)
        )
      )
    )
    (gnn_layers): Sequential(
      (0): GCNConvGNNLayer(
        (conv): GCNConv(128, 128)
        (dropout): Dropout(p=0.0, inplace=False)
        (activation): GELU(approximate='none')
      )
      (1): GCNConvGNNLayer(
        (conv): GCNConv(128, 128)
        (dropout): Dropout(p=0.0, inplace=False)
        (activation): GELU(approximate='none')
      )
      (2): GCNConvGNNLayer(
        (conv): GCNConv(128, 128)
        (dropout): Dropout(p=0.0, inplace=False)
        (activation): GELU(approximate='none')
      )
      (3): GCNConvGNNLayer(
        (conv): GCNConv(128, 128)
        (dropout): Dropout(p=0.0, inplace=False)
        (activation): GELU(approximate='none')
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (mlp): Sequential(
        (0): Dropout(p=0.0, inplace=False)
        (1): Linear(in_features=128, out_features=6, bias=True)
      )
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  arxiv_year:
    num_split: 0
    with_ogbn_arxiv_labels: False
  associative_recall:
    n_graphs: (25000, 500, 500)
    num_keys: 1
    num_vocab: 30
    precalc_eigdec_k: 10
    test_n_nodes: (1000, 1200)
    train_n_nodes: (20, 1000)
    valid_n_nodes: (20, 1000)
  cache_load: False
  cache_save: False
  custom_cluster:
    gmm_cluster_from_posterior: True
    gmm_dim: 2
    gmm_edges_max: 10
    gmm_edges_min: 1
    gmm_range_clusters: 10
    gmm_std_clusters: 2
    graph_type: gmm
    n_clusters: 6
    n_graphs: (10000, 1000, 1000)
    random_p: 0.55
    random_q: 0.25
    size_max: 200
    size_min: 100
  dir: ./datasets
  edge_dim: 128
  edge_encoder: False
  edge_encoder_bn: True
  edge_encoder_name: Bond
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: synthetic
  label_column: none
  label_table: none
  location: local
  name: custom-cluster-gmm
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LinearNode+MagLapPE
  node_encoder_num_types: 0
  ogbn_arxiv:
    mask_rate: 0.5
    use_labels: True
  over_squashing:
    gen_mode: full
    n_classes: 5
    n_graphs: (5000, 500, 5000)
    test_n_nodes: (52, 100)
    topology: ring_lollipop
    train_n_nodes: (4, 50)
    valid_n_nodes: (4, 50)
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  source_dist:
    n_graphs: (50000, 2500, 2500)
    p_add_edges_from_tree: 0
    test_n_nodes: (1100, 1200)
    train_n_nodes: (500, 1000)
    valid_n_nodes: (1000, 1100)
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  tpu_graphs:
    config_node_readout: False
    custom: False
    drop_high_deg_sinks: False
    drop_high_deg_sources: False
    drop_last_node_above_deg: -1
    encoder_factor: 100.0
    include_valid_in_train: False
    normalize: False
    search: ['random']
    source: ['nlp']
    subsample: 500
    tpu_task: layout
  transductive: False
  transform: none
  tu_simple: True
device: cuda
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: gelu
  adj_norm: dir
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: False
  batchnorm_post_mp: False
  clear_feature: True
  dim_inner: 128
  dir_aggr: cat
  dropout: 0.0
  gatconv:
    attn_dropout: 0.05
    backend: PyG
    feat_dropout: 0.75
    negative_slope: 0.2
    norm: True
    num_heads: 3
    pre_dropout: 0.1
    with_linear: True
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_skip: []
  layer_type: gcnconv
  layernorm_post_mp: False
  layers_mp: 4
  layers_post_mp: 1
  layers_pre_mp: 0
  make_undirected: True
  msg_direction: single
  node_dropout: 0.0
  normalize_adj: False
  residual: True
  self_msg: concat
  skip_every: 1
  spectral:
    basis_bottleneck: 0.25
    basis_init_type: default
    basis_num_gaussians: 50
    combine_with_spatial: None
    combine_with_spatial_norm: True
    dropout: -1.0
    eigv_scale: -1
    feature_transform: None
    filter_encoder: basis
    filter_layers: 1
    filter_value_trans: None
    filter_variant: naive
    frequency_cutoff: None
    layer_skip: [0, 1, 2, 3]
    learnable_norm: False
    learnable_norm_init: 0
    mlp_layers_filter_encoder: 2
    num_heads_filter_encoder: -1
    readout: None
    readout_residual: False
    readout_sepnorm: False
    real_imag_x_merge: None
    residual: True
    window: None
  stage_type: stack
  use_edge_attr: False
gpu_mem: False
gt:
  attn_dropout: 0.0
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  dim_hidden: 64
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: SANLayer
  layers: 3
  n_heads: 8
  pna_degrees: []
  residual: True
mem:
  inplace: False
metric_agg: argmax
metric_best: accuracy-SBM
model:
  edge_decoding: dot
  graph_pooling: add
  list_mle_divisor: 250
  loss_fun: weighted_cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: s2gnn
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.003
  batch_accumulation: 1
  clip_grad_norm: True
  last_layer_no_wd: False
  lr_decay: 0.1
  max_epoch: 50
  min_lr: 0.0
  model_averaging: None
  model_averaging_start: 0
  momentum: 0.9
  num_warmup_epochs: 5
  optimizer: adamW
  quasi_alternating: -1
  reduce_factor: 0.1
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  stop_patience: 1000
  weight_decay: 0.0001
out_dir: tests/results/custom-cluster/gmm-gcnconv-pe/2025-05-12/11-33-06-909867-custom-cluster-gmm-gcnconv-pe
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_MagLapPE:
  dim_pe: 0
  drop_trailing_repeated: False
  enable: True
  kwargs:
    sigma: 0
  laplacian_norm: sym
  largest_connected_component: False
  layers: 3
  max_freqs: 10
  model: none
  n_heads: 4
  pass_as_var: False
  positional_encoding: False
  post_layers: 0
  precompute: False
  q: 0.0
  raw_norm_type: none
  sparse: True
  which: LM
  window: tukey
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: False
print: both
round: 5
run_dir: tests/results/custom-cluster/gmm-gcnconv-pe/2025-05-12/11-33-06-909867-custom-cluster-gmm-gcnconv-pe/13
run_id: 13
run_multiple_splits: []
seed: 13
share:
  dim_in: 7
  dim_out: 6
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: False
train:
  auto_resume: False
  batch_size: 50
  ckpt_best: True
  ckpt_clean: True
  ckpt_data_attrs: ['y', 'pred', 'batch']
  ckpt_data_splits: ['val', 'test']
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  num_sample_configs: 16
  radius: extend
  sample_node: False
  sampler: full_batch
  scale_num_sample_configs: True
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  num_sample_batch: 100
  num_sample_configs: 1000
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: tum_i26
  name: 
  project: cluster
  tags: 
  use: False
Num parameters: 69254
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 54.26261, 'eta': 2658.86797, 'eta_hours': 0.73857, 'loss': 1.8778846, 'lr': 0.0, 'params': 69254, 'time_iter': 0.27131, 'accuracy': 0.16628, 'f1': 0.04753, 'accuracy-SBM': 0.16598, 'auc': 0.50978}
...computing epoch stats took: 1.38s
val: {'epoch': 0, 'time_epoch': 4.00625, 'loss': 1.8789352, 'lr': 0, 'params': 69254, 'time_iter': 0.20031, 'accuracy': 0.16559, 'f1': 0.04736, 'accuracy-SBM': 0.16597, 'auc': 0.51003}
...computing epoch stats took: 0.40s
test: {'epoch': 0, 'time_epoch': 4.20612, 'loss': 1.87775935, 'lr': 0, 'params': 69254, 'time_iter': 0.21031, 'accuracy': 0.16687, 'f1': 0.04767, 'accuracy-SBM': 0.16601, 'auc': 0.50992}
...computing epoch stats took: 0.37s
> Epoch 0: took 64.6s (avg 64.6s) | Best so far: epoch 0	train loss: 1.8779 train_accuracy-SBM: 0.1660	val loss: 1.8789 val_accuracy-SBM: 0.1660	test loss: 1.8778 test_accuracy-SBM: 0.1660
train: {'epoch': 1, 'time_epoch': 50.80925, 'eta': 2521.72459, 'eta_hours': 0.70048, 'loss': 1.76546473, 'lr': 0.0006, 'params': 69254, 'time_iter': 0.25405, 'accuracy': 0.22576, 'f1': 0.2256, 'accuracy-SBM': 0.22576, 'auc': 0.55342}
...computing epoch stats took: 1.35s
val: {'epoch': 1, 'time_epoch': 3.84566, 'loss': 1.69248776, 'lr': 0, 'params': 69254, 'time_iter': 0.19228, 'accuracy': 0.26638, 'f1': 0.22844, 'accuracy-SBM': 0.26598, 'auc': 0.64926}
...computing epoch stats took: 0.38s
test: {'epoch': 1, 'time_epoch': 3.81386, 'loss': 1.693922, 'lr': 0, 'params': 69254, 'time_iter': 0.19069, 'accuracy': 0.26429, 'f1': 0.22626, 'accuracy-SBM': 0.26461, 'auc': 0.64812}
...computing epoch stats took: 0.37s
> Epoch 1: took 60.6s (avg 62.6s) | Best so far: epoch 1	train loss: 1.7655 train_accuracy-SBM: 0.2258	val loss: 1.6925 val_accuracy-SBM: 0.2660	test loss: 1.6939 test_accuracy-SBM: 0.2646
train: {'epoch': 2, 'time_epoch': 50.71087, 'eta': 2440.59603, 'eta_hours': 0.67794, 'loss': 1.66389367, 'lr': 0.0012, 'params': 69254, 'time_iter': 0.25355, 'accuracy': 0.28602, 'f1': 0.28256, 'accuracy-SBM': 0.2861, 'auc': 0.61952}
...computing epoch stats took: 1.38s
val: {'epoch': 2, 'time_epoch': 3.8041, 'loss': 1.60682144, 'lr': 0, 'params': 69254, 'time_iter': 0.1902, 'accuracy': 0.32877, 'f1': 0.31554, 'accuracy-SBM': 0.3273, 'auc': 0.68721}
...computing epoch stats took: 0.37s
test: {'epoch': 2, 'time_epoch': 3.86691, 'loss': 1.60908942, 'lr': 0, 'params': 69254, 'time_iter': 0.19335, 'accuracy': 0.32461, 'f1': 0.31212, 'accuracy-SBM': 0.32552, 'auc': 0.68604}
...computing epoch stats took: 0.37s
> Epoch 2: took 60.5s (avg 61.9s) | Best so far: epoch 2	train loss: 1.6639 train_accuracy-SBM: 0.2861	val loss: 1.6068 val_accuracy-SBM: 0.3273	test loss: 1.6091 test_accuracy-SBM: 0.3255
train: {'epoch': 3, 'time_epoch': 49.56044, 'eta': 2361.44638, 'eta_hours': 0.65596, 'loss': 1.60175902, 'lr': 0.0018, 'params': 69254, 'time_iter': 0.2478, 'accuracy': 0.32455, 'f1': 0.32409, 'accuracy-SBM': 0.3246, 'auc': 0.65681}
val: {'epoch': 3, 'time_epoch': 3.86857, 'loss': 1.58514654, 'lr': 0, 'params': 69254, 'time_iter': 0.19343, 'accuracy': 0.33366, 'f1': 0.3315, 'accuracy-SBM': 0.33327, 'auc': 0.70622}
test: {'epoch': 3, 'time_epoch': 3.79592, 'loss': 1.58590553, 'lr': 0, 'params': 69254, 'time_iter': 0.1898, 'accuracy': 0.33245, 'f1': 0.33048, 'accuracy-SBM': 0.3326, 'auc': 0.70539}
> Epoch 3: took 59.4s (avg 61.3s) | Best so far: epoch 3	train loss: 1.6018 train_accuracy-SBM: 0.3246	val loss: 1.5851 val_accuracy-SBM: 0.3333	test loss: 1.5859 test_accuracy-SBM: 0.3326
train: {'epoch': 4, 'time_epoch': 50.74919, 'eta': 2304.83122, 'eta_hours': 0.64023, 'loss': 1.59478461, 'lr': 0.0024, 'params': 69254, 'time_iter': 0.25375, 'accuracy': 0.3338, 'f1': 0.3339, 'accuracy-SBM': 0.33385, 'auc': 0.66564}
val: {'epoch': 4, 'time_epoch': 3.83633, 'loss': 1.55228781, 'lr': 0, 'params': 69254, 'time_iter': 0.19182, 'accuracy': 0.37774, 'f1': 0.37769, 'accuracy-SBM': 0.37772, 'auc': 0.72727}
test: {'epoch': 4, 'time_epoch': 3.90652, 'loss': 1.55196508, 'lr': 0, 'params': 69254, 'time_iter': 0.19533, 'accuracy': 0.37718, 'f1': 0.37658, 'accuracy-SBM': 0.37682, 'auc': 0.72701}
> Epoch 4: took 60.7s (avg 61.2s) | Best so far: epoch 4	train loss: 1.5948 train_accuracy-SBM: 0.3338	val loss: 1.5523 val_accuracy-SBM: 0.3777	test loss: 1.5520 test_accuracy-SBM: 0.3768
train: {'epoch': 5, 'time_epoch': 50.6577, 'eta': 2249.50046, 'eta_hours': 0.62486, 'loss': 1.54312427, 'lr': 0.003, 'params': 69254, 'time_iter': 0.25329, 'accuracy': 0.35958, 'f1': 0.36048, 'accuracy-SBM': 0.3596, 'auc': 0.69049}
val: {'epoch': 5, 'time_epoch': 3.84308, 'loss': 1.62983695, 'lr': 0, 'params': 69254, 'time_iter': 0.19215, 'accuracy': 0.34798, 'f1': 0.34761, 'accuracy-SBM': 0.34852, 'auc': 0.73117}
test: {'epoch': 5, 'time_epoch': 3.82709, 'loss': 1.62713839, 'lr': 0, 'params': 69254, 'time_iter': 0.19135, 'accuracy': 0.34838, 'f1': 0.34753, 'accuracy-SBM': 0.34827, 'auc': 0.73083}
> Epoch 5: took 60.5s (avg 61.1s) | Best so far: epoch 4	train loss: 1.5948 train_accuracy-SBM: 0.3338	val loss: 1.5523 val_accuracy-SBM: 0.3777	test loss: 1.5520 test_accuracy-SBM: 0.3768
train: {'epoch': 6, 'time_epoch': 50.70976, 'eta': 2195.82463, 'eta_hours': 0.60995, 'loss': 1.48434024, 'lr': 0.00299635, 'params': 69254, 'time_iter': 0.25355, 'accuracy': 0.38702, 'f1': 0.3882, 'accuracy-SBM': 0.38706, 'auc': 0.71702}
val: {'epoch': 6, 'time_epoch': 3.9216, 'loss': 1.46695221, 'lr': 0, 'params': 69254, 'time_iter': 0.19608, 'accuracy': 0.37845, 'f1': 0.39375, 'accuracy-SBM': 0.3787, 'auc': 0.75505}
test: {'epoch': 6, 'time_epoch': 3.8041, 'loss': 1.46618233, 'lr': 0, 'params': 69254, 'time_iter': 0.19021, 'accuracy': 0.37862, 'f1': 0.3931, 'accuracy-SBM': 0.37801, 'auc': 0.7549}
> Epoch 6: took 60.7s (avg 61.0s) | Best so far: epoch 6	train loss: 1.4843 train_accuracy-SBM: 0.3871	val loss: 1.4670 val_accuracy-SBM: 0.3787	test loss: 1.4662 test_accuracy-SBM: 0.3780
train: {'epoch': 7, 'time_epoch': 50.80154, 'eta': 2143.37217, 'eta_hours': 0.59538, 'loss': 1.44889987, 'lr': 0.0029854, 'params': 69254, 'time_iter': 0.25401, 'accuracy': 0.41159, 'f1': 0.41432, 'accuracy-SBM': 0.41162, 'auc': 0.7358}
val: {'epoch': 7, 'time_epoch': 3.89927, 'loss': 1.49416429, 'lr': 0, 'params': 69254, 'time_iter': 0.19496, 'accuracy': 0.40838, 'f1': 0.42727, 'accuracy-SBM': 0.40799, 'auc': 0.7589}
test: {'epoch': 7, 'time_epoch': 3.72098, 'loss': 1.49383632, 'lr': 0, 'params': 69254, 'time_iter': 0.18605, 'accuracy': 0.40763, 'f1': 0.42696, 'accuracy-SBM': 0.40772, 'auc': 0.7584}
> Epoch 7: took 60.7s (avg 61.0s) | Best so far: epoch 7	train loss: 1.4489 train_accuracy-SBM: 0.4116	val loss: 1.4942 val_accuracy-SBM: 0.4080	test loss: 1.4938 test_accuracy-SBM: 0.4077
train: {'epoch': 8, 'time_epoch': 49.78506, 'eta': 2086.65596, 'eta_hours': 0.57963, 'loss': 1.40920161, 'lr': 0.00296722, 'params': 69254, 'time_iter': 0.24893, 'accuracy': 0.43322, 'f1': 0.43512, 'accuracy-SBM': 0.43326, 'auc': 0.75456}
val: {'epoch': 8, 'time_epoch': 3.88721, 'loss': 1.37055451, 'lr': 0, 'params': 69254, 'time_iter': 0.19436, 'accuracy': 0.44949, 'f1': 0.47814, 'accuracy-SBM': 0.44975, 'auc': 0.77415}
test: {'epoch': 8, 'time_epoch': 3.8714, 'loss': 1.36736384, 'lr': 0, 'params': 69254, 'time_iter': 0.19357, 'accuracy': 0.45029, 'f1': 0.47897, 'accuracy-SBM': 0.44954, 'auc': 0.77413}
> Epoch 8: took 59.7s (avg 60.8s) | Best so far: epoch 8	train loss: 1.4092 train_accuracy-SBM: 0.4333	val loss: 1.3706 val_accuracy-SBM: 0.4497	test loss: 1.3674 test_accuracy-SBM: 0.4495
train: {'epoch': 9, 'time_epoch': 50.07371, 'eta': 2032.48058, 'eta_hours': 0.56458, 'loss': 1.36921085, 'lr': 0.00294189, 'params': 69254, 'time_iter': 0.25037, 'accuracy': 0.44828, 'f1': 0.44998, 'accuracy-SBM': 0.44831, 'auc': 0.76881}
val: {'epoch': 9, 'time_epoch': 3.76154, 'loss': 1.35309837, 'lr': 0, 'params': 69254, 'time_iter': 0.18808, 'accuracy': 0.44771, 'f1': 0.46329, 'accuracy-SBM': 0.44787, 'auc': 0.77568}
test: {'epoch': 9, 'time_epoch': 3.6873, 'loss': 1.35332753, 'lr': 0, 'params': 69254, 'time_iter': 0.18436, 'accuracy': 0.44794, 'f1': 0.46245, 'accuracy-SBM': 0.44793, 'auc': 0.77564}
> Epoch 9: took 59.6s (avg 60.7s) | Best so far: epoch 8	train loss: 1.4092 train_accuracy-SBM: 0.4333	val loss: 1.3706 val_accuracy-SBM: 0.4497	test loss: 1.3674 test_accuracy-SBM: 0.4495
train: {'epoch': 10, 'time_epoch': 49.17329, 'eta': 1975.85853, 'eta_hours': 0.54885, 'loss': 1.34703839, 'lr': 0.00290954, 'params': 69254, 'time_iter': 0.24587, 'accuracy': 0.45267, 'f1': 0.45384, 'accuracy-SBM': 0.45269, 'auc': 0.77415}
val: {'epoch': 10, 'time_epoch': 3.77461, 'loss': 1.3363141, 'lr': 0, 'params': 69254, 'time_iter': 0.18873, 'accuracy': 0.45234, 'f1': 0.48195, 'accuracy-SBM': 0.45284, 'auc': 0.77809}
test: {'epoch': 10, 'time_epoch': 3.70945, 'loss': 1.33665423, 'lr': 0, 'params': 69254, 'time_iter': 0.18547, 'accuracy': 0.45275, 'f1': 0.48258, 'accuracy-SBM': 0.45323, 'auc': 0.77772}
> Epoch 10: took 58.8s (avg 60.5s) | Best so far: epoch 10	train loss: 1.3470 train_accuracy-SBM: 0.4527	val loss: 1.3363 val_accuracy-SBM: 0.4528	test loss: 1.3367 test_accuracy-SBM: 0.4532
train: {'epoch': 11, 'time_epoch': 49.3352, 'eta': 1920.99065, 'eta_hours': 0.53361, 'loss': 1.3320999, 'lr': 0.00287032, 'params': 69254, 'time_iter': 0.24668, 'accuracy': 0.45429, 'f1': 0.45488, 'accuracy-SBM': 0.45431, 'auc': 0.77678}
val: {'epoch': 11, 'time_epoch': 3.74284, 'loss': 1.32505924, 'lr': 0, 'params': 69254, 'time_iter': 0.18714, 'accuracy': 0.4547, 'f1': 0.47048, 'accuracy-SBM': 0.4549, 'auc': 0.77885}
test: {'epoch': 11, 'time_epoch': 3.7122, 'loss': 1.32348491, 'lr': 0, 'params': 69254, 'time_iter': 0.18561, 'accuracy': 0.45483, 'f1': 0.47076, 'accuracy-SBM': 0.45491, 'auc': 0.77863}
> Epoch 11: took 58.9s (avg 60.4s) | Best so far: epoch 11	train loss: 1.3321 train_accuracy-SBM: 0.4543	val loss: 1.3251 val_accuracy-SBM: 0.4549	test loss: 1.3235 test_accuracy-SBM: 0.4549
train: {'epoch': 12, 'time_epoch': 47.40372, 'eta': 1861.47669, 'eta_hours': 0.51708, 'loss': 1.32158057, 'lr': 0.00282442, 'params': 69254, 'time_iter': 0.23702, 'accuracy': 0.4552, 'f1': 0.45558, 'accuracy-SBM': 0.45521, 'auc': 0.77843}
val: {'epoch': 12, 'time_epoch': 3.72113, 'loss': 1.31736604, 'lr': 0, 'params': 69254, 'time_iter': 0.18606, 'accuracy': 0.4553, 'f1': 0.48497, 'accuracy-SBM': 0.45554, 'auc': 0.77955}
test: {'epoch': 12, 'time_epoch': 3.81856, 'loss': 1.31792813, 'lr': 0, 'params': 69254, 'time_iter': 0.19093, 'accuracy': 0.45493, 'f1': 0.48377, 'accuracy-SBM': 0.45443, 'auc': 0.7793}
> Epoch 12: took 57.1s (avg 60.1s) | Best so far: epoch 12	train loss: 1.3216 train_accuracy-SBM: 0.4552	val loss: 1.3174 val_accuracy-SBM: 0.4555	test loss: 1.3179 test_accuracy-SBM: 0.4544
train: {'epoch': 13, 'time_epoch': 50.82654, 'eta': 1812.4943, 'eta_hours': 0.50347, 'loss': 1.31695779, 'lr': 0.00277207, 'params': 69254, 'time_iter': 0.25413, 'accuracy': 0.45464, 'f1': 0.45502, 'accuracy-SBM': 0.45465, 'auc': 0.77879}
val: {'epoch': 13, 'time_epoch': 3.80329, 'loss': 1.30998973, 'lr': 0, 'params': 69254, 'time_iter': 0.19016, 'accuracy': 0.45691, 'f1': 0.48609, 'accuracy-SBM': 0.45588, 'auc': 0.77896}
test: {'epoch': 13, 'time_epoch': 3.82821, 'loss': 1.31069386, 'lr': 0, 'params': 69254, 'time_iter': 0.19141, 'accuracy': 0.45378, 'f1': 0.48345, 'accuracy-SBM': 0.4544, 'auc': 0.77905}
> Epoch 13: took 60.7s (avg 60.2s) | Best so far: epoch 13	train loss: 1.3170 train_accuracy-SBM: 0.4546	val loss: 1.3100 val_accuracy-SBM: 0.4559	test loss: 1.3107 test_accuracy-SBM: 0.4544
train: {'epoch': 14, 'time_epoch': 50.79031, 'eta': 1763.18147, 'eta_hours': 0.48977, 'loss': 1.31238879, 'lr': 0.00271353, 'params': 69254, 'time_iter': 0.25395, 'accuracy': 0.45533, 'f1': 0.45593, 'accuracy-SBM': 0.45534, 'auc': 0.77941}
val: {'epoch': 14, 'time_epoch': 3.93233, 'loss': 1.3106861, 'lr': 0, 'params': 69254, 'time_iter': 0.19662, 'accuracy': 0.45296, 'f1': 0.48256, 'accuracy-SBM': 0.45346, 'auc': 0.77908}
test: {'epoch': 14, 'time_epoch': 3.82883, 'loss': 1.31103429, 'lr': 0, 'params': 69254, 'time_iter': 0.19144, 'accuracy': 0.45322, 'f1': 0.48302, 'accuracy-SBM': 0.4537, 'auc': 0.7789}
> Epoch 14: took 60.8s (avg 60.2s) | Best so far: epoch 13	train loss: 1.3170 train_accuracy-SBM: 0.4546	val loss: 1.3100 val_accuracy-SBM: 0.4559	test loss: 1.3107 test_accuracy-SBM: 0.4544
train: {'epoch': 15, 'time_epoch': 50.79832, 'eta': 1713.70098, 'eta_hours': 0.47603, 'loss': 1.31068838, 'lr': 0.00264907, 'params': 69254, 'time_iter': 0.25399, 'accuracy': 0.4547, 'f1': 0.45492, 'accuracy-SBM': 0.4547, 'auc': 0.77933}
val: {'epoch': 15, 'time_epoch': 3.8176, 'loss': 1.31121448, 'lr': 0, 'params': 69254, 'time_iter': 0.19088, 'accuracy': 0.45696, 'f1': 0.48536, 'accuracy-SBM': 0.45594, 'auc': 0.7793}
test: {'epoch': 15, 'time_epoch': 3.81432, 'loss': 1.31138953, 'lr': 0, 'params': 69254, 'time_iter': 0.19072, 'accuracy': 0.45365, 'f1': 0.48253, 'accuracy-SBM': 0.45426, 'auc': 0.7791}
> Epoch 15: took 60.6s (avg 60.2s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 16, 'time_epoch': 50.76988, 'eta': 1664.01024, 'eta_hours': 0.46223, 'loss': 1.30965266, 'lr': 0.00257901, 'params': 69254, 'time_iter': 0.25385, 'accuracy': 0.45477, 'f1': 0.4555, 'accuracy-SBM': 0.45477, 'auc': 0.77956}
val: {'epoch': 16, 'time_epoch': 3.93743, 'loss': 1.30907469, 'lr': 0, 'params': 69254, 'time_iter': 0.19687, 'accuracy': 0.45304, 'f1': 0.48219, 'accuracy-SBM': 0.45355, 'auc': 0.77917}
test: {'epoch': 16, 'time_epoch': 3.75751, 'loss': 1.30869647, 'lr': 0, 'params': 69254, 'time_iter': 0.18788, 'accuracy': 0.45315, 'f1': 0.4825, 'accuracy-SBM': 0.45363, 'auc': 0.77907}
> Epoch 16: took 60.6s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 17, 'time_epoch': 49.51888, 'eta': 1611.9756, 'eta_hours': 0.44777, 'loss': 1.30777984, 'lr': 0.0025037, 'params': 69254, 'time_iter': 0.24759, 'accuracy': 0.45473, 'f1': 0.45484, 'accuracy-SBM': 0.45473, 'auc': 0.77954}
val: {'epoch': 17, 'time_epoch': 3.81778, 'loss': 1.30600188, 'lr': 0, 'params': 69254, 'time_iter': 0.19089, 'accuracy': 0.45471, 'f1': 0.48429, 'accuracy-SBM': 0.45513, 'auc': 0.77953}
test: {'epoch': 17, 'time_epoch': 3.80444, 'loss': 1.30585589, 'lr': 0, 'params': 69254, 'time_iter': 0.19022, 'accuracy': 0.45458, 'f1': 0.48372, 'accuracy-SBM': 0.45456, 'auc': 0.77938}
> Epoch 17: took 59.3s (avg 60.2s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 18, 'time_epoch': 50.80392, 'eta': 1562.30243, 'eta_hours': 0.43397, 'loss': 1.31058737, 'lr': 0.00242349, 'params': 69254, 'time_iter': 0.25402, 'accuracy': 0.45538, 'f1': 0.45563, 'accuracy-SBM': 0.45539, 'auc': 0.77929}
val: {'epoch': 18, 'time_epoch': 3.96426, 'loss': 1.30730668, 'lr': 0, 'params': 69254, 'time_iter': 0.19821, 'accuracy': 0.45466, 'f1': 0.48412, 'accuracy-SBM': 0.45508, 'auc': 0.77929}
test: {'epoch': 18, 'time_epoch': 3.81131, 'loss': 1.30714104, 'lr': 0, 'params': 69254, 'time_iter': 0.19057, 'accuracy': 0.45457, 'f1': 0.48362, 'accuracy-SBM': 0.45456, 'auc': 0.77914}
> Epoch 18: took 60.9s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 19, 'time_epoch': 50.98733, 'eta': 1512.79129, 'eta_hours': 0.42022, 'loss': 1.30682775, 'lr': 0.00233879, 'params': 69254, 'time_iter': 0.25494, 'accuracy': 0.45463, 'f1': 0.455, 'accuracy-SBM': 0.45462, 'auc': 0.77964}
val: {'epoch': 19, 'time_epoch': 3.81334, 'loss': 1.30682389, 'lr': 0, 'params': 69254, 'time_iter': 0.19067, 'accuracy': 0.45302, 'f1': 0.48263, 'accuracy-SBM': 0.45352, 'auc': 0.77981}
test: {'epoch': 19, 'time_epoch': 3.88838, 'loss': 1.30680676, 'lr': 0, 'params': 69254, 'time_iter': 0.19442, 'accuracy': 0.45326, 'f1': 0.48305, 'accuracy-SBM': 0.45374, 'auc': 0.77936}
> Epoch 19: took 60.9s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 20, 'time_epoch': 50.81908, 'eta': 1462.90722, 'eta_hours': 0.40636, 'loss': 1.30570005, 'lr': 0.00225, 'params': 69254, 'time_iter': 0.2541, 'accuracy': 0.4548, 'f1': 0.45499, 'accuracy-SBM': 0.45479, 'auc': 0.77965}
val: {'epoch': 20, 'time_epoch': 3.84934, 'loss': 1.30377587, 'lr': 0, 'params': 69254, 'time_iter': 0.19247, 'accuracy': 0.45554, 'f1': 0.48439, 'accuracy-SBM': 0.45523, 'auc': 0.77971}
test: {'epoch': 20, 'time_epoch': 3.81672, 'loss': 1.30408009, 'lr': 0, 'params': 69254, 'time_iter': 0.19084, 'accuracy': 0.45487, 'f1': 0.48423, 'accuracy-SBM': 0.45505, 'auc': 0.77942}
> Epoch 20: took 60.6s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 21, 'time_epoch': 49.60238, 'eta': 1411.38962, 'eta_hours': 0.39205, 'loss': 1.30459718, 'lr': 0.00215756, 'params': 69254, 'time_iter': 0.24801, 'accuracy': 0.45425, 'f1': 0.45448, 'accuracy-SBM': 0.45425, 'auc': 0.77953}
val: {'epoch': 21, 'time_epoch': 3.83536, 'loss': 1.30245648, 'lr': 0, 'params': 69254, 'time_iter': 0.19177, 'accuracy': 0.45579, 'f1': 0.47847, 'accuracy-SBM': 0.45556, 'auc': 0.77986}
test: {'epoch': 21, 'time_epoch': 3.80923, 'loss': 1.30238469, 'lr': 0, 'params': 69254, 'time_iter': 0.19046, 'accuracy': 0.45468, 'f1': 0.47784, 'accuracy-SBM': 0.45477, 'auc': 0.77976}
> Epoch 21: took 59.4s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 22, 'time_epoch': 50.84249, 'eta': 1361.49434, 'eta_hours': 0.37819, 'loss': 1.30384213, 'lr': 0.00206191, 'params': 69254, 'time_iter': 0.25421, 'accuracy': 0.45481, 'f1': 0.45493, 'accuracy-SBM': 0.45481, 'auc': 0.77984}
val: {'epoch': 22, 'time_epoch': 3.88121, 'loss': 1.30311492, 'lr': 0, 'params': 69254, 'time_iter': 0.19406, 'accuracy': 0.45294, 'f1': 0.48255, 'accuracy-SBM': 0.45345, 'auc': 0.78005}
test: {'epoch': 22, 'time_epoch': 3.82594, 'loss': 1.30334292, 'lr': 0, 'params': 69254, 'time_iter': 0.1913, 'accuracy': 0.45319, 'f1': 0.48298, 'accuracy-SBM': 0.45366, 'auc': 0.77967}
> Epoch 22: took 60.8s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 23, 'time_epoch': 50.7406, 'eta': 1311.40975, 'eta_hours': 0.36428, 'loss': 1.30320732, 'lr': 0.00196353, 'params': 69254, 'time_iter': 0.2537, 'accuracy': 0.45496, 'f1': 0.45519, 'accuracy-SBM': 0.45496, 'auc': 0.77998}
val: {'epoch': 23, 'time_epoch': 4.086, 'loss': 1.30299814, 'lr': 0, 'params': 69254, 'time_iter': 0.2043, 'accuracy': 0.45697, 'f1': 0.48618, 'accuracy-SBM': 0.45594, 'auc': 0.78007}
test: {'epoch': 23, 'time_epoch': 3.87065, 'loss': 1.30386452, 'lr': 0, 'params': 69254, 'time_iter': 0.19353, 'accuracy': 0.45369, 'f1': 0.48334, 'accuracy-SBM': 0.45431, 'auc': 0.77954}
> Epoch 23: took 60.8s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 24, 'time_epoch': 50.73928, 'eta': 1261.27136, 'eta_hours': 0.35035, 'loss': 1.30285383, 'lr': 0.00186288, 'params': 69254, 'time_iter': 0.2537, 'accuracy': 0.45503, 'f1': 0.45512, 'accuracy-SBM': 0.45503, 'auc': 0.77971}
val: {'epoch': 24, 'time_epoch': 3.82586, 'loss': 1.30164173, 'lr': 0, 'params': 69254, 'time_iter': 0.19129, 'accuracy': 0.45456, 'f1': 0.48152, 'accuracy-SBM': 0.45497, 'auc': 0.77979}
test: {'epoch': 24, 'time_epoch': 3.79355, 'loss': 1.30188498, 'lr': 0, 'params': 69254, 'time_iter': 0.18968, 'accuracy': 0.45454, 'f1': 0.48113, 'accuracy-SBM': 0.45454, 'auc': 0.77968}
> Epoch 24: took 60.6s (avg 60.3s) | Best so far: epoch 15	train loss: 1.3107 train_accuracy-SBM: 0.4547	val loss: 1.3112 val_accuracy-SBM: 0.4559	test loss: 1.3114 test_accuracy-SBM: 0.4543
train: {'epoch': 25, 'time_epoch': 50.86764, 'eta': 1211.20523, 'eta_hours': 0.33645, 'loss': 1.30277311, 'lr': 0.00176047, 'params': 69254, 'time_iter': 0.25434, 'accuracy': 0.45482, 'f1': 0.45506, 'accuracy-SBM': 0.45481, 'auc': 0.77995}
val: {'epoch': 25, 'time_epoch': 3.97485, 'loss': 1.30241913, 'lr': 0, 'params': 69254, 'time_iter': 0.19874, 'accuracy': 0.45703, 'f1': 0.48635, 'accuracy-SBM': 0.456, 'auc': 0.77988}
test: {'epoch': 25, 'time_epoch': 3.82093, 'loss': 1.30318914, 'lr': 0, 'params': 69254, 'time_iter': 0.19105, 'accuracy': 0.45361, 'f1': 0.48337, 'accuracy-SBM': 0.45423, 'auc': 0.77968}
> Epoch 25: took 60.9s (avg 60.3s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 26, 'time_epoch': 49.46375, 'eta': 1159.88382, 'eta_hours': 0.32219, 'loss': 1.30168866, 'lr': 0.00165679, 'params': 69254, 'time_iter': 0.24732, 'accuracy': 0.45493, 'f1': 0.45545, 'accuracy-SBM': 0.45491, 'auc': 0.77999}
val: {'epoch': 26, 'time_epoch': 3.85448, 'loss': 1.30177233, 'lr': 0, 'params': 69254, 'time_iter': 0.19272, 'accuracy': 0.45297, 'f1': 0.48263, 'accuracy-SBM': 0.45348, 'auc': 0.77977}
test: {'epoch': 26, 'time_epoch': 3.81541, 'loss': 1.30207714, 'lr': 0, 'params': 69254, 'time_iter': 0.19077, 'accuracy': 0.45319, 'f1': 0.483, 'accuracy-SBM': 0.45367, 'auc': 0.77961}
> Epoch 26: took 59.3s (avg 60.3s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 27, 'time_epoch': 50.98041, 'eta': 1109.88677, 'eta_hours': 0.3083, 'loss': 1.30128625, 'lr': 0.00155235, 'params': 69254, 'time_iter': 0.2549, 'accuracy': 0.45502, 'f1': 0.45508, 'accuracy-SBM': 0.45503, 'auc': 0.78007}
val: {'epoch': 27, 'time_epoch': 3.9067, 'loss': 1.29947967, 'lr': 0, 'params': 69254, 'time_iter': 0.19534, 'accuracy': 0.45696, 'f1': 0.48621, 'accuracy-SBM': 0.45592, 'auc': 0.78018}
test: {'epoch': 27, 'time_epoch': 3.82128, 'loss': 1.30001527, 'lr': 0, 'params': 69254, 'time_iter': 0.19106, 'accuracy': 0.4537, 'f1': 0.48341, 'accuracy-SBM': 0.45431, 'auc': 0.77983}
> Epoch 27: took 61.1s (avg 60.3s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 28, 'time_epoch': 50.76921, 'eta': 1059.66895, 'eta_hours': 0.29435, 'loss': 1.30117134, 'lr': 0.00144765, 'params': 69254, 'time_iter': 0.25385, 'accuracy': 0.45472, 'f1': 0.45497, 'accuracy-SBM': 0.45472, 'auc': 0.77983}
val: {'epoch': 28, 'time_epoch': 3.82327, 'loss': 1.30050735, 'lr': 0, 'params': 69254, 'time_iter': 0.19116, 'accuracy': 0.45531, 'f1': 0.48477, 'accuracy-SBM': 0.45554, 'auc': 0.78013}
test: {'epoch': 28, 'time_epoch': 3.81563, 'loss': 1.30053769, 'lr': 0, 'params': 69254, 'time_iter': 0.19078, 'accuracy': 0.45483, 'f1': 0.48342, 'accuracy-SBM': 0.45433, 'auc': 0.77987}
> Epoch 28: took 61.1s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 29, 'time_epoch': 50.83816, 'eta': 1009.46034, 'eta_hours': 0.28041, 'loss': 1.30092411, 'lr': 0.00134321, 'params': 69254, 'time_iter': 0.25419, 'accuracy': 0.455, 'f1': 0.456, 'accuracy-SBM': 0.45499, 'auc': 0.78012}
val: {'epoch': 29, 'time_epoch': 3.93029, 'loss': 1.30043276, 'lr': 0, 'params': 69254, 'time_iter': 0.19651, 'accuracy': 0.45383, 'f1': 0.4718, 'accuracy-SBM': 0.4543, 'auc': 0.78019}
test: {'epoch': 29, 'time_epoch': 3.83734, 'loss': 1.30047886, 'lr': 0, 'params': 69254, 'time_iter': 0.19187, 'accuracy': 0.45358, 'f1': 0.47191, 'accuracy-SBM': 0.45384, 'auc': 0.77943}
> Epoch 29: took 60.8s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 30, 'time_epoch': 49.56417, 'eta': 958.43029, 'eta_hours': 0.26623, 'loss': 1.30033879, 'lr': 0.00123953, 'params': 69254, 'time_iter': 0.24782, 'accuracy': 0.45457, 'f1': 0.45514, 'accuracy-SBM': 0.45455, 'auc': 0.78014}
val: {'epoch': 30, 'time_epoch': 3.80259, 'loss': 1.29888482, 'lr': 0, 'params': 69254, 'time_iter': 0.19013, 'accuracy': 0.457, 'f1': 0.48627, 'accuracy-SBM': 0.45597, 'auc': 0.78066}
test: {'epoch': 30, 'time_epoch': 3.83307, 'loss': 1.29943459, 'lr': 0, 'params': 69254, 'time_iter': 0.19165, 'accuracy': 0.45372, 'f1': 0.48345, 'accuracy-SBM': 0.45434, 'auc': 0.78004}
> Epoch 30: took 59.3s (avg 60.3s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 31, 'time_epoch': 50.85763, 'eta': 908.21943, 'eta_hours': 0.25228, 'loss': 1.29975452, 'lr': 0.00113712, 'params': 69254, 'time_iter': 0.25429, 'accuracy': 0.45502, 'f1': 0.4553, 'accuracy-SBM': 0.45501, 'auc': 0.78014}
val: {'epoch': 31, 'time_epoch': 3.88271, 'loss': 1.29895727, 'lr': 0, 'params': 69254, 'time_iter': 0.19414, 'accuracy': 0.45512, 'f1': 0.48311, 'accuracy-SBM': 0.45539, 'auc': 0.7801}
test: {'epoch': 31, 'time_epoch': 3.82525, 'loss': 1.29925284, 'lr': 0, 'params': 69254, 'time_iter': 0.19126, 'accuracy': 0.4557, 'f1': 0.4837, 'accuracy-SBM': 0.45498, 'auc': 0.77981}
> Epoch 31: took 60.7s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 32, 'time_epoch': 50.67801, 'eta': 857.87684, 'eta_hours': 0.2383, 'loss': 1.29914936, 'lr': 0.00103647, 'params': 69254, 'time_iter': 0.25339, 'accuracy': 0.45526, 'f1': 0.45572, 'accuracy-SBM': 0.45526, 'auc': 0.78043}
val: {'epoch': 32, 'time_epoch': 3.8971, 'loss': 1.29894199, 'lr': 0, 'params': 69254, 'time_iter': 0.19486, 'accuracy': 0.45557, 'f1': 0.47379, 'accuracy-SBM': 0.45555, 'auc': 0.78051}
test: {'epoch': 32, 'time_epoch': 3.8225, 'loss': 1.29897398, 'lr': 0, 'params': 69254, 'time_iter': 0.19113, 'accuracy': 0.45463, 'f1': 0.47333, 'accuracy-SBM': 0.45473, 'auc': 0.78002}
> Epoch 32: took 60.6s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 33, 'time_epoch': 50.683, 'eta': 807.51686, 'eta_hours': 0.22431, 'loss': 1.29897896, 'lr': 0.00093809, 'params': 69254, 'time_iter': 0.25341, 'accuracy': 0.45489, 'f1': 0.45535, 'accuracy-SBM': 0.45489, 'auc': 0.7804}
val: {'epoch': 33, 'time_epoch': 3.9388, 'loss': 1.29880059, 'lr': 0, 'params': 69254, 'time_iter': 0.19694, 'accuracy': 0.45478, 'f1': 0.48394, 'accuracy-SBM': 0.45519, 'auc': 0.78017}
test: {'epoch': 33, 'time_epoch': 3.81154, 'loss': 1.29951429, 'lr': 0, 'params': 69254, 'time_iter': 0.19058, 'accuracy': 0.45456, 'f1': 0.48328, 'accuracy-SBM': 0.45454, 'auc': 0.78019}
> Epoch 33: took 60.7s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 34, 'time_epoch': 50.81868, 'eta': 757.19658, 'eta_hours': 0.21033, 'loss': 1.29873319, 'lr': 0.00084244, 'params': 69254, 'time_iter': 0.25409, 'accuracy': 0.45479, 'f1': 0.45533, 'accuracy-SBM': 0.45478, 'auc': 0.78017}
val: {'epoch': 34, 'time_epoch': 3.92075, 'loss': 1.29937259, 'lr': 0, 'params': 69254, 'time_iter': 0.19604, 'accuracy': 0.45467, 'f1': 0.48424, 'accuracy-SBM': 0.45509, 'auc': 0.78057}
test: {'epoch': 34, 'time_epoch': 3.79898, 'loss': 1.29972729, 'lr': 0, 'params': 69254, 'time_iter': 0.18995, 'accuracy': 0.45444, 'f1': 0.48355, 'accuracy-SBM': 0.45442, 'auc': 0.78001}
> Epoch 34: took 60.8s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 35, 'time_epoch': 49.53471, 'eta': 706.34928, 'eta_hours': 0.19621, 'loss': 1.29837083, 'lr': 0.00075, 'params': 69254, 'time_iter': 0.24767, 'accuracy': 0.4547, 'f1': 0.45508, 'accuracy-SBM': 0.45468, 'auc': 0.78004}
val: {'epoch': 35, 'time_epoch': 3.89694, 'loss': 1.29828917, 'lr': 0, 'params': 69254, 'time_iter': 0.19485, 'accuracy': 0.45334, 'f1': 0.47838, 'accuracy-SBM': 0.45384, 'auc': 0.78021}
test: {'epoch': 35, 'time_epoch': 3.8244, 'loss': 1.29920056, 'lr': 0, 'params': 69254, 'time_iter': 0.19122, 'accuracy': 0.45315, 'f1': 0.4785, 'accuracy-SBM': 0.45358, 'auc': 0.77982}
> Epoch 35: took 59.5s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 36, 'time_epoch': 50.75024, 'eta': 656.00002, 'eta_hours': 0.18222, 'loss': 1.29808631, 'lr': 0.00066121, 'params': 69254, 'time_iter': 0.25375, 'accuracy': 0.4545, 'f1': 0.45508, 'accuracy-SBM': 0.45448, 'auc': 0.78002}
val: {'epoch': 36, 'time_epoch': 3.79388, 'loss': 1.29700058, 'lr': 0, 'params': 69254, 'time_iter': 0.18969, 'accuracy': 0.45698, 'f1': 0.4862, 'accuracy-SBM': 0.45594, 'auc': 0.7805}
test: {'epoch': 36, 'time_epoch': 3.82619, 'loss': 1.2976903, 'lr': 0, 'params': 69254, 'time_iter': 0.19131, 'accuracy': 0.45362, 'f1': 0.48331, 'accuracy-SBM': 0.45424, 'auc': 0.78035}
> Epoch 36: took 60.6s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 37, 'time_epoch': 50.73642, 'eta': 605.62528, 'eta_hours': 0.16823, 'loss': 1.29767989, 'lr': 0.00057651, 'params': 69254, 'time_iter': 0.25368, 'accuracy': 0.45467, 'f1': 0.45508, 'accuracy-SBM': 0.45467, 'auc': 0.78024}
val: {'epoch': 37, 'time_epoch': 3.8376, 'loss': 1.2975754, 'lr': 0, 'params': 69254, 'time_iter': 0.19188, 'accuracy': 0.45695, 'f1': 0.48625, 'accuracy-SBM': 0.45592, 'auc': 0.78026}
test: {'epoch': 37, 'time_epoch': 3.81509, 'loss': 1.29895328, 'lr': 0, 'params': 69254, 'time_iter': 0.19075, 'accuracy': 0.45365, 'f1': 0.48341, 'accuracy-SBM': 0.45427, 'auc': 0.77997}
> Epoch 37: took 60.6s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 38, 'time_epoch': 50.82326, 'eta': 555.25649, 'eta_hours': 0.15424, 'loss': 1.29756252, 'lr': 0.0004963, 'params': 69254, 'time_iter': 0.25412, 'accuracy': 0.45487, 'f1': 0.45552, 'accuracy-SBM': 0.45485, 'auc': 0.78022}
val: {'epoch': 38, 'time_epoch': 3.90935, 'loss': 1.29690333, 'lr': 0, 'params': 69254, 'time_iter': 0.19547, 'accuracy': 0.45558, 'f1': 0.48455, 'accuracy-SBM': 0.45528, 'auc': 0.78081}
test: {'epoch': 38, 'time_epoch': 3.79265, 'loss': 1.29734123, 'lr': 0, 'params': 69254, 'time_iter': 0.18963, 'accuracy': 0.45491, 'f1': 0.48435, 'accuracy-SBM': 0.45509, 'auc': 0.78044}
> Epoch 38: took 60.7s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 39, 'time_epoch': 49.52047, 'eta': 504.53928, 'eta_hours': 0.14015, 'loss': 1.2971062, 'lr': 0.00042099, 'params': 69254, 'time_iter': 0.2476, 'accuracy': 0.45507, 'f1': 0.4563, 'accuracy-SBM': 0.45505, 'auc': 0.78053}
val: {'epoch': 39, 'time_epoch': 3.89624, 'loss': 1.2964917, 'lr': 0, 'params': 69254, 'time_iter': 0.19481, 'accuracy': 0.45698, 'f1': 0.48622, 'accuracy-SBM': 0.45595, 'auc': 0.78055}
test: {'epoch': 39, 'time_epoch': 3.85111, 'loss': 1.29748763, 'lr': 0, 'params': 69254, 'time_iter': 0.19256, 'accuracy': 0.45364, 'f1': 0.48333, 'accuracy-SBM': 0.45426, 'auc': 0.78035}
> Epoch 39: took 59.5s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 40, 'time_epoch': 50.71078, 'eta': 454.14173, 'eta_hours': 0.12615, 'loss': 1.29676059, 'lr': 0.00035093, 'params': 69254, 'time_iter': 0.25355, 'accuracy': 0.4554, 'f1': 0.45583, 'accuracy-SBM': 0.4554, 'auc': 0.78106}
val: {'epoch': 40, 'time_epoch': 3.81134, 'loss': 1.29641603, 'lr': 0, 'params': 69254, 'time_iter': 0.19057, 'accuracy': 0.45556, 'f1': 0.48433, 'accuracy-SBM': 0.45525, 'auc': 0.78092}
test: {'epoch': 40, 'time_epoch': 3.81424, 'loss': 1.2970442, 'lr': 0, 'params': 69254, 'time_iter': 0.19071, 'accuracy': 0.45483, 'f1': 0.48409, 'accuracy-SBM': 0.45501, 'auc': 0.78028}
> Epoch 40: took 60.6s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 41, 'time_epoch': 50.79925, 'eta': 403.74613, 'eta_hours': 0.11215, 'loss': 1.29666239, 'lr': 0.00028647, 'params': 69254, 'time_iter': 0.254, 'accuracy': 0.45478, 'f1': 0.45529, 'accuracy-SBM': 0.45479, 'auc': 0.7805}
val: {'epoch': 41, 'time_epoch': 3.90334, 'loss': 1.29598535, 'lr': 0, 'params': 69254, 'time_iter': 0.19517, 'accuracy': 0.45694, 'f1': 0.48614, 'accuracy-SBM': 0.45591, 'auc': 0.78026}
test: {'epoch': 41, 'time_epoch': 3.82073, 'loss': 1.29668785, 'lr': 0, 'params': 69254, 'time_iter': 0.19104, 'accuracy': 0.45363, 'f1': 0.48328, 'accuracy-SBM': 0.45425, 'auc': 0.78035}
> Epoch 41: took 60.8s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 42, 'time_epoch': 50.66667, 'eta': 353.31016, 'eta_hours': 0.09814, 'loss': 1.29621809, 'lr': 0.00022793, 'params': 69254, 'time_iter': 0.25333, 'accuracy': 0.45463, 'f1': 0.45553, 'accuracy-SBM': 0.4546, 'auc': 0.7805}
val: {'epoch': 42, 'time_epoch': 3.88273, 'loss': 1.295577, 'lr': 0, 'params': 69254, 'time_iter': 0.19414, 'accuracy': 0.45534, 'f1': 0.48489, 'accuracy-SBM': 0.45558, 'auc': 0.78061}
test: {'epoch': 42, 'time_epoch': 3.84043, 'loss': 1.29644935, 'lr': 0, 'params': 69254, 'time_iter': 0.19202, 'accuracy': 0.45487, 'f1': 0.48354, 'accuracy-SBM': 0.45437, 'auc': 0.78047}
> Epoch 42: took 60.6s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 43, 'time_epoch': 50.88087, 'eta': 302.89291, 'eta_hours': 0.08414, 'loss': 1.29615964, 'lr': 0.00017558, 'params': 69254, 'time_iter': 0.2544, 'accuracy': 0.45493, 'f1': 0.45589, 'accuracy-SBM': 0.45491, 'auc': 0.78047}
val: {'epoch': 43, 'time_epoch': 3.89285, 'loss': 1.29574646, 'lr': 0, 'params': 69254, 'time_iter': 0.19464, 'accuracy': 0.45555, 'f1': 0.48405, 'accuracy-SBM': 0.45525, 'auc': 0.78035}
test: {'epoch': 43, 'time_epoch': 3.80069, 'loss': 1.29630819, 'lr': 0, 'params': 69254, 'time_iter': 0.19003, 'accuracy': 0.45489, 'f1': 0.48384, 'accuracy-SBM': 0.45507, 'auc': 0.78043}
> Epoch 43: took 60.8s (avg 60.4s) | Best so far: epoch 25	train loss: 1.3028 train_accuracy-SBM: 0.4548	val loss: 1.3024 val_accuracy-SBM: 0.4560	test loss: 1.3032 test_accuracy-SBM: 0.4542
train: {'epoch': 44, 'time_epoch': 46.89392, 'eta': 252.01207, 'eta_hours': 0.07, 'loss': 1.29586356, 'lr': 0.00012968, 'params': 69254, 'time_iter': 0.23447, 'accuracy': 0.45507, 'f1': 0.45598, 'accuracy-SBM': 0.45505, 'auc': 0.78086}
val: {'epoch': 44, 'time_epoch': 3.55463, 'loss': 1.2957432, 'lr': 0, 'params': 69254, 'time_iter': 0.17773, 'accuracy': 0.45711, 'f1': 0.48345, 'accuracy-SBM': 0.45614, 'auc': 0.78068}
test: {'epoch': 44, 'time_epoch': 3.42768, 'loss': 1.29613497, 'lr': 0, 'params': 69254, 'time_iter': 0.17138, 'accuracy': 0.45368, 'f1': 0.48063, 'accuracy-SBM': 0.45423, 'auc': 0.78052}
> Epoch 44: took 56.0s (avg 60.3s) | Best so far: epoch 44	train loss: 1.2959 train_accuracy-SBM: 0.4551	val loss: 1.2957 val_accuracy-SBM: 0.4561	test loss: 1.2961 test_accuracy-SBM: 0.4542
train: {'epoch': 45, 'time_epoch': 44.44696, 'eta': 201.09179, 'eta_hours': 0.05586, 'loss': 1.29570238, 'lr': 9.046e-05, 'params': 69254, 'time_iter': 0.22223, 'accuracy': 0.45533, 'f1': 0.45702, 'accuracy-SBM': 0.45535, 'auc': 0.78069}
val: {'epoch': 45, 'time_epoch': 3.40282, 'loss': 1.29556505, 'lr': 0, 'params': 69254, 'time_iter': 0.17014, 'accuracy': 0.4554, 'f1': 0.48453, 'accuracy-SBM': 0.45564, 'auc': 0.78067}
test: {'epoch': 45, 'time_epoch': 3.3913, 'loss': 1.29596044, 'lr': 0, 'params': 69254, 'time_iter': 0.16956, 'accuracy': 0.45486, 'f1': 0.4831, 'accuracy-SBM': 0.45437, 'auc': 0.78049}
> Epoch 45: took 53.4s (avg 60.1s) | Best so far: epoch 44	train loss: 1.2959 train_accuracy-SBM: 0.4551	val loss: 1.2957 val_accuracy-SBM: 0.4561	test loss: 1.2961 test_accuracy-SBM: 0.4542
train: {'epoch': 46, 'time_epoch': 44.37887, 'eta': 150.44262, 'eta_hours': 0.04179, 'loss': 1.29554901, 'lr': 5.811e-05, 'params': 69254, 'time_iter': 0.22189, 'accuracy': 0.45482, 'f1': 0.45563, 'accuracy-SBM': 0.45483, 'auc': 0.7807}
val: {'epoch': 46, 'time_epoch': 3.42541, 'loss': 1.29505333, 'lr': 0, 'params': 69254, 'time_iter': 0.17127, 'accuracy': 0.45649, 'f1': 0.47911, 'accuracy-SBM': 0.45566, 'auc': 0.7807}
test: {'epoch': 46, 'time_epoch': 3.45768, 'loss': 1.29579833, 'lr': 0, 'params': 69254, 'time_iter': 0.17288, 'accuracy': 0.45387, 'f1': 0.47702, 'accuracy-SBM': 0.45428, 'auc': 0.78048}
> Epoch 46: took 53.4s (avg 60.0s) | Best so far: epoch 44	train loss: 1.2959 train_accuracy-SBM: 0.4551	val loss: 1.2957 val_accuracy-SBM: 0.4561	test loss: 1.2961 test_accuracy-SBM: 0.4542
train: {'epoch': 47, 'time_epoch': 44.63642, 'eta': 100.06545, 'eta_hours': 0.0278, 'loss': 1.29544178, 'lr': 3.278e-05, 'params': 69254, 'time_iter': 0.22318, 'accuracy': 0.4551, 'f1': 0.46015, 'accuracy-SBM': 0.45509, 'auc': 0.78067}
val: {'epoch': 47, 'time_epoch': 3.3301, 'loss': 1.29503794, 'lr': 0, 'params': 69254, 'time_iter': 0.1665, 'accuracy': 0.45633, 'f1': 0.47209, 'accuracy-SBM': 0.45585, 'auc': 0.78061}
test: {'epoch': 47, 'time_epoch': 3.41351, 'loss': 1.29570687, 'lr': 0, 'params': 69254, 'time_iter': 0.17068, 'accuracy': 0.45387, 'f1': 0.46899, 'accuracy-SBM': 0.45402, 'auc': 0.78049}
> Epoch 47: took 53.5s (avg 59.9s) | Best so far: epoch 44	train loss: 1.2959 train_accuracy-SBM: 0.4551	val loss: 1.2957 val_accuracy-SBM: 0.4561	test loss: 1.2961 test_accuracy-SBM: 0.4542
train: {'epoch': 48, 'time_epoch': 44.42081, 'eta': 49.9182, 'eta_hours': 0.01387, 'loss': 1.29534614, 'lr': 1.46e-05, 'params': 69254, 'time_iter': 0.2221, 'accuracy': 0.45504, 'f1': 0.45889, 'accuracy-SBM': 0.45502, 'auc': 0.78059}
val: {'epoch': 48, 'time_epoch': 3.46541, 'loss': 1.29495547, 'lr': 0, 'params': 69254, 'time_iter': 0.17327, 'accuracy': 0.45695, 'f1': 0.48595, 'accuracy-SBM': 0.45592, 'auc': 0.7807}
test: {'epoch': 48, 'time_epoch': 3.33219, 'loss': 1.29562689, 'lr': 0, 'params': 69254, 'time_iter': 0.16661, 'accuracy': 0.45362, 'f1': 0.4831, 'accuracy-SBM': 0.45423, 'auc': 0.78046}
> Epoch 48: took 53.3s (avg 59.7s) | Best so far: epoch 44	train loss: 1.2959 train_accuracy-SBM: 0.4551	val loss: 1.2957 val_accuracy-SBM: 0.4561	test loss: 1.2961 test_accuracy-SBM: 0.4542
train: {'epoch': 49, 'time_epoch': 44.39869, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 1.29527973, 'lr': 3.65e-06, 'params': 69254, 'time_iter': 0.22199, 'accuracy': 0.45517, 'f1': 0.4663, 'accuracy-SBM': 0.45509, 'auc': 0.78066}
val: {'epoch': 49, 'time_epoch': 3.39383, 'loss': 1.2949525, 'lr': 0, 'params': 69254, 'time_iter': 0.16969, 'accuracy': 0.45696, 'f1': 0.48591, 'accuracy-SBM': 0.45593, 'auc': 0.78068}
test: {'epoch': 49, 'time_epoch': 3.33181, 'loss': 1.2956119, 'lr': 0, 'params': 69254, 'time_iter': 0.16659, 'accuracy': 0.45361, 'f1': 0.48306, 'accuracy-SBM': 0.45423, 'auc': 0.78049}
> Epoch 49: took 53.3s (avg 59.6s) | Best so far: epoch 44	train loss: 1.2959 train_accuracy-SBM: 0.4551	val loss: 1.2957 val_accuracy-SBM: 0.4561	test loss: 1.2961 test_accuracy-SBM: 0.4542
Avg time per epoch: 59.60s
Total train loop time: 0.83h
Task done, results saved in tests/results/custom-cluster/gmm-gcnconv-pe/2025-05-12/11-33-06-909867-custom-cluster-gmm-gcnconv-pe/13
Failed when trying to aggregate multiple runs: Tensorboard support requires `tensorboardX`.
[*] All done: 2025-05-12 12:24:42.327809
